"""
데이터 조회, 파일 입출력 등 공통으로 사용되는 유틸리티 함수 모음.
"""

import functools
import json
import logging
import os
import warnings
from collections.abc import Iterable, Sequence
from contextlib import contextmanager
from datetime import datetime, time
from typing import Any

import pandas as pd

# pkg_resources 워닝 억제 (가장 강력한 방법)
os.environ["PYTHONWARNINGS"] = "ignore"
warnings.simplefilter("ignore")
warnings.filterwarnings("ignore", message="pkg_resources is deprecated", category=UserWarning)
warnings.filterwarnings("ignore", message="pkg_resources is deprecated as an API")
warnings.filterwarnings("ignore", category=UserWarning, module="pykrx")

# 웹 스크레이핑을 위한 라이브러리
try:
    import requests
    from bs4 import BeautifulSoup
except ImportError:
    requests = None
    BeautifulSoup = None

# yfinance가 설치되지 않았을 경우를 대비한 예외 처리
try:
    import yfinance as yf
except ImportError:
    yf = None

# pykrx가 설치되지 않았을 경우를 대비한 예외 처리
try:
    from pykrx import stock as _stock
except Exception:
    _stock = None

# from utils.notification import send_verbose_log_to_slack
import warnings

from config import MARKET_SCHEDULES
from utils.cache_utils import load_cached_frame, load_cached_frames_bulk, save_cached_frame
from utils.logger import get_app_logger
from utils.stock_list_io import get_etfs_by_country, get_listing_date, set_listing_date

# ... (omitted code)

warnings.filterwarnings("ignore", message="pkg_resources is deprecated")
warnings.filterwarnings(
    "ignore",
    message=r"\['break_start', 'break_end'\] are discontinued",
    category=UserWarning,
    module=r"^pandas_market_calendars\.",
)


class _PykrxLogFilter(logging.Filter):
    """형식이 무너지는 pykrx util 로그를 억제한다."""  # pragma: no cover - 로그 정리 목적

    def filter(self, record: logging.LogRecord) -> bool:
        msg = record.msg
        args = record.args
        if (
            isinstance(msg, tuple)
            and len(msg) == 3
            and all(isinstance(m, str) for m in msg)
            and isinstance(args, tuple)
            and len(args) == 1
            and isinstance(args[0], dict)
            and not args[0]
        ):
            return False
        try:
            formatted = record.getMessage()
        except Exception:  # pragma: no cover - defensive
            formatted = ""
        if "None of [Index(['" in formatted:
            return False
        return True


_root_logger = logging.getLogger()
if not any(isinstance(f, _PykrxLogFilter) for f in _root_logger.filters):
    _root_logger.addFilter(_PykrxLogFilter())

logger = get_app_logger()


def _safe_float(value: Any) -> float | None:
    try:
        return float(value)
    except (TypeError, ValueError):
        return None


try:
    from zoneinfo import ZoneInfo
except ImportError:  # pragma: no cover
    ZoneInfo = None  # type: ignore


class PykrxDataUnavailableError(Exception):
    """pykrx 데이터가 제공되지 않을 때 사용되는 예외."""

    # Custom Exception implementation for clearer Error suffix
    pass

    def __init__(
        self,
        country: str,
        start_dt: pd.Timestamp,
        end_dt: pd.Timestamp,
        detail: str,
    ) -> None:
        self.country = country
        self.start_dt = start_dt
        self.end_dt = end_dt
        self.detail = detail
        message = f"[{country.upper()}] pykrx data unavailable ({start_dt.date()}~{end_dt.date()}): {detail}"
        super().__init__(message)


class RateLimitError(Exception):
    """API rate limit에 도달했을 때 사용되는 예외."""

    def __init__(self, ticker: str, detail: str) -> None:
        self.ticker = ticker
        self.detail = detail
        message = f"Rate limit exceeded for {ticker}: {detail}"
        super().__init__(message)


class MissingPriceDataError(RuntimeError):
    """필수 가격 데이터가 비어 있을 때 발생시키는 예외."""

    def __init__(
        self,
        *,
        country: str,
        start_date: str | pd.Timestamp | None,
        end_date: str | pd.Timestamp | None,
        tickers: Iterable[str],
    ) -> None:
        self.country = (country or "").strip().lower()
        self.start_date = pd.to_datetime(start_date).strftime("%Y-%m-%d") if start_date else None
        self.end_date = pd.to_datetime(end_date).strftime("%Y-%m-%d") if end_date else None
        normalized = sorted({str(t).strip().upper() for t in tickers if str(t).strip()})
        self.tickers = normalized
        period = ""
        if self.start_date or self.end_date:
            period = f" ({self.start_date or '?'}~{self.end_date or '?'})"
        message = (
            f"[{(self.country or 'unknown').upper()}] "
            f"가격 데이터 누락{period}: {len(normalized)}개 종목 미존재 ({', '.join(normalized)})"
        )
        super().__init__(message)


def _get_cache_start_dt() -> pd.Timestamp | None:
    """config.py에서 캐시 시작 날짜를 로드합니다."""
    try:
        from utils.settings_loader import load_common_settings

        common_settings = load_common_settings()
        raw = common_settings.get("CACHE_START_DATE")
    except Exception:
        return None

    if not raw:
        return None

    try:
        dt = pd.to_datetime(raw)
    except Exception:
        return None
    if isinstance(dt, pd.DatetimeIndex):
        dt = dt[0]
    if isinstance(dt, pd.Timestamp):
        if dt.tzinfo is not None:
            dt = dt.tz_localize(None)
        return dt.normalize()
    return None


def _should_skip_pykrx_fetch(
    country: str,
    cache_end: pd.Timestamp | None,
    miss_start: pd.Timestamp,
) -> bool:
    """장 시작 전에는 캐시만 사용하도록 pykrx 호출을 지연합니다."""

    country_code = (country or "").strip().lower()

    if country_code != "kor" or cache_end is None:
        return False

    if ZoneInfo is not None:
        now_local = datetime.now(ZoneInfo("Asia/Seoul"))
    else:  # pragma: no cover
        now_local = datetime.now()

    # pykrx 데이터가 당일 분이 아직 나오지 않은 장 시작 전(16시 이전)이라면 생략
    if miss_start.normalize() == pd.Timestamp(now_local.date()) and now_local.hour < 16:
        return True

    return False


def _now_with_zone(tz_name: str) -> datetime:
    try:
        if ZoneInfo is not None:
            return datetime.now(ZoneInfo(tz_name))
    except Exception:
        pass
    return datetime.now()


def _build_market_open_info() -> dict[str, tuple[str, time]]:
    info: dict[str, tuple[str, time]] = {}
    for code, schedule in (MARKET_SCHEDULES or {}).items():
        if not isinstance(schedule, dict):
            continue
        open_time = schedule.get("open") or time(9, 0)
        tz_name = schedule.get("timezone") or "UTC"
        info[code.lower()] = (tz_name, open_time)
    return info


MARKET_OPEN_INFO = _build_market_open_info()


def _should_skip_today_range(country_code: str, target_end: pd.Timestamp) -> bool:
    if ZoneInfo is None:
        return False

    info = MARKET_OPEN_INFO.get((country_code or "").strip().lower())
    if not info:
        return False

    tz_name, open_time = info
    try:
        now_local = _now_with_zone(tz_name)
    except Exception:
        return False

    if target_end.normalize() != pd.Timestamp(now_local.date()):
        return False

    if now_local.time() >= open_time:
        return False

    return True


def _is_time_in_window(now_dt: datetime, start: time, end: time) -> bool:
    current = now_dt.time()
    return start <= current <= end


@contextmanager
def _silence_yfinance_logs():
    import logging

    targets = [
        logging.getLogger("yfinance"),
        logging.getLogger("yfinance.utils"),
        logging.getLogger("yfinance.data"),
    ]
    prev_levels = [lg.level for lg in targets]
    try:
        for lg in targets:
            lg.setLevel(logging.CRITICAL)
        yield
    finally:
        for lg, lvl in zip(targets, prev_levels):
            lg.setLevel(lvl)


def get_today_str() -> str:
    """오늘 날짜를 'YYYYMMDD' 형식의 문자열로 반환합니다."""
    return datetime.now().strftime("%Y%m%d")


@functools.lru_cache(maxsize=10)
def get_trading_days(start_date: str, end_date: str, country: str) -> list[pd.Timestamp]:
    """
    지정된 기간 내의 모든 거래일을 pd.Timestamp 리스트로 반환합니다.
    한국(KRX)는 pandas_market_calendars만 사용합니다.
    """
    trading_days_ts: list[pd.Timestamp] = []

    def _pmc(country_code: str) -> list[pd.Timestamp]:
        import pandas_market_calendars as mcal  # type: ignore

        cal_code = {"kor": "XKRX", "us": "NYSE", "au": "XASX"}.get(country_code)
        if not cal_code:
            return []
        try:
            cal = mcal.get_calendar(cal_code)
            # 최신 pandas_market_calendars에서는 폐지된 장중 시간대를 새 API로 제거합니다.
            try:
                dmt = getattr(cal, "discontinued_market_times", {})
                for tname in getattr(dmt, "keys", lambda: [])():
                    try:
                        cal.remove_time(tname)  # type: ignore[attr-defined]
                    except Exception:
                        pass
            except Exception:
                # 이전 버전에서는 기존 방식으로 폴백합니다.
                for tname in ("break_start", "break_end"):
                    try:
                        cal.remove_time(tname)  # type: ignore[attr-defined]
                    except Exception:
                        pass

            # 가능하다면 날짜만 반환하는 valid_days 결과를 우선 사용합니다.
            try:
                days_idx = cal.valid_days(start_date=start_date, end_date=end_date)
                if days_idx is not None and len(days_idx) > 0:
                    return [pd.Timestamp(pd.Timestamp(d).date()) for d in days_idx]
            except Exception:
                pass

            # 위 단계가 실패하면 schedule 기반으로 폴백하고 폐기 경고를 숨깁니다.
            with warnings.catch_warnings():
                warnings.filterwarnings(
                    "ignore",
                    message=r"\['break_start', 'break_end'\] are discontinued",
                    category=UserWarning,
                )
                sched = cal.schedule(start_date=start_date, end_date=end_date)
            if sched is not None and not sched.empty:
                return [pd.Timestamp(d.date()) for d in sched.index]
        except Exception as e:
            logger.warning("pandas_market_calendars(%s:%s) 조회 실패: %s", country_code, cal_code, e)
        return []

    country_code = (country or "").strip().lower()

    if country_code in ("kor", "us", "au"):
        trading_days_ts = _pmc(country_code)
    else:
        logger.error("지원하지 않는 국가 코드입니다: %s", country_code)
        return []

    # 최종적으로 start_date와 end_date 사이의 날짜만 반환하고, 중복 제거 및 정렬합니다.
    start_date_ts = pd.to_datetime(start_date).normalize()
    end_date_ts = pd.to_datetime(end_date).normalize()
    final_list = [d for d in trading_days_ts if start_date_ts <= d <= end_date_ts]

    return sorted(list(set(final_list)))


def is_trading_day(
    country: str,
    date: str | datetime | pd.Timestamp | None = None,
) -> bool:
    """주어진 날짜가 해당 국가의 거래일인지 여부를 반환합니다."""

    target = pd.Timestamp(date if date is not None else datetime.now())
    target = target.tz_localize(None) if getattr(target, "tzinfo", None) else target
    target_norm = target.normalize()
    date_str = target_norm.strftime("%Y-%m-%d")

    try:
        return bool(get_trading_days(date_str, date_str, country))
    except Exception:
        return False


def count_trading_days(
    country: str,
    start_date: str | datetime | pd.Timestamp,
    end_date: str | datetime | pd.Timestamp,
) -> int:
    """Return number of trading days between two dates (inclusive)."""

    start_ts = pd.to_datetime(start_date).normalize()
    end_ts = pd.to_datetime(end_date).normalize()

    if start_ts > end_ts:
        return 0

    country_code = (country or "").strip().lower()

    # 캐시를 위해 문자열로 변환하여 내부 함수 호출
    return _count_trading_days_cached(country_code, start_ts.strftime("%Y-%m-%d"), end_ts.strftime("%Y-%m-%d"))


@functools.lru_cache(maxsize=500)
def _count_trading_days_cached(country_code: str, start_str: str, end_str: str) -> int:
    """캐시된 거래일 수 계산 (내부 함수)"""
    days = get_trading_days(start_str, end_str, country_code)
    return len(days)


@functools.lru_cache(maxsize=50)
def _get_latest_trading_day_cached(country: str, cache_key: str) -> pd.Timestamp:
    """
    내부 캐시 함수: 날짜/시간 기반 캐시 키를 사용하여 최신 거래일을 반환합니다.

    Args:
        country: 국가 코드
        cache_key: 캐시 무효화용 키 (날짜_시간 형식)
    """
    country_code = (country or "").strip().lower()

    end_dt = pd.Timestamp.now()

    tz_info = MARKET_OPEN_INFO.get(country_code)
    if tz_info is not None:
        tz_name, open_time = tz_info
        try:
            local_now = _now_with_zone(tz_name)
            candidate_date = local_now.date()

            # [User Request] 장 개시 전이라도 오늘이 거래일이면 오늘 날짜를 반환 (0% 수익률 표시용)
            if local_now.time() < open_time:
                candidate_date = candidate_date - pd.Timedelta(days=1)

            end_dt = pd.Timestamp(candidate_date)
        except Exception:
            # 타임존 처리 실패 시 안전하게 폴백
            pass
    elif country_code == "kor":
        # 한국 시장: 타임존 정보를 사용하도록 통합
        try:
            from datetime import datetime

            import pytz

            tz = pytz.timezone("Asia/Seoul")
            local_now = datetime.now(tz)
            end_dt = pd.Timestamp(local_now.date())
        except Exception:
            end_dt = end_dt.normalize()
    else:
        # 타임존 정보를 모르면 현재 날짜 기준으로 처리
        end_dt = end_dt.normalize()

    # 최근 10일간의 거래일을 한 번에 조회 (효율성 개선)
    start_date = (end_dt - pd.DateOffset(days=10)).strftime("%Y-%m-%d")
    end_date = end_dt.strftime("%Y-%m-%d")

    try:
        # 최근 10일간의 모든 거래일을 한 번에 가져옴
        trading_days = get_trading_days(start_date, end_date, country_code)

        if trading_days:
            # 가장 최근 거래일을 반환
            latest_trading_day = max(trading_days)
            return latest_trading_day.normalize()
    except Exception as e:
        logger.warning("거래일 일괄 조회 중 오류 발생: %s", e)

    # 폴백: 10일간 거래일을 찾지 못하면 오늘 날짜를 정규화하여 반환합니다.
    logger.warning(
        "최근 10일 내에 거래일을 찾지 못했습니다. 오늘 날짜(%s)를 사용합니다.",
        end_dt.strftime("%Y-%m-%d"),
    )
    return end_dt.normalize()


def get_latest_trading_day(country: str) -> pd.Timestamp:
    """
    오늘 또는 가장 가까운 과거의 '데이터가 있을 것으로 예상되는' 거래일을 pd.Timestamp 형식으로 반환합니다.

    시간 기반 캐시를 사용하여 날짜가 바뀌거나 시간이 지나면 자동으로 캐시가 무효화됩니다.
    """
    # 현재 날짜와 시간(시 단위)을 캐시 키로 사용
    # 이렇게 하면 매 시간마다 캐시가 갱신되어 장 시작 전/후 데이터 차이를 반영
    now = pd.Timestamp.now()
    cache_key = f"{now.strftime('%Y-%m-%d')}_{now.hour}"
    return _get_latest_trading_day_cached(country, cache_key)


def get_next_trading_day(
    country: str,
    reference_date: pd.Timestamp | None = None,
    *,
    search_horizon_days: int = 30,
) -> pd.Timestamp | None:
    """reference_date 이후의 다음 거래일을 반환한다."""

    country_code = (country or "").strip().lower()
    ref = (reference_date or pd.Timestamp.now()).normalize()
    search_end = ref + pd.DateOffset(days=search_horizon_days)

    trading_days = get_trading_days(ref.strftime("%Y-%m-%d"), search_end.strftime("%Y-%m-%d"), country_code)
    for day in trading_days:
        day_norm = pd.Timestamp(day).normalize()
        if day_norm > ref:
            return day_norm
    return None


def fetch_ohlcv(
    ticker: str,
    country: str = "kor",
    months_back: int = None,
    date_range: list[str | None] | None = None,
    base_date: pd.Timestamp | None = None,
    *,
    account_id: str | None = None,
    force_refresh: bool = False,
    update_listing_meta: bool = False,
) -> pd.DataFrame | None:
    """OHLCV 데이터를 조회합니다. 캐시를 우선 사용하고 부족분만 원천에서 보충합니다."""

    country_code = (country or "").strip().lower() or "kor"

    if date_range and len(date_range) == 2:
        try:  # date_range가 있으면, 다른 기간 인자들을 무시하고 이를 기준으로 start_dt, end_dt를 설정합니다.
            start_dt = pd.to_datetime(date_range[0])
            if date_range[1] is None:
                # date_range의 두 번째 인자가 None이면 오늘까지 조회합니다.
                end_dt = pd.to_datetime(get_today_str())
            else:
                end_dt = pd.to_datetime(date_range[1])
        except (ValueError, TypeError):
            logger.error("잘못된 date_range 형식: %s. 'YYYY-MM-DD' 형식을 사용해야 합니다.", date_range)
            return None
    else:
        now = base_date if base_date is not None else pd.Timestamp.now()
        months_back = months_back or 3  # months_back의 기본값은 3개월
        start_dt = now - pd.DateOffset(months=int(months_back))
        end_dt = now

    # 조회 종료일(end_dt)이 실제 데이터가 있는 마지막 거래일을 초과하지 않도록 보정합니다.
    # 이는 주말이나 휴일에 다음 거래일을 기준으로 데이터를 조회할 때, 아직 존재하지 않는
    # 미래 데이터를 조회하려는 시도를 방지합니다.
    latest_known_trading_day = get_latest_trading_day(country_code)
    if end_dt > latest_known_trading_day:
        end_dt = latest_known_trading_day

    if start_dt > end_dt:
        # 보정 후 시작일이 종료일보다 미래가 될 수 있으므로, 이 경우 데이터를 조회하지 않습니다.
        return None

    df = _fetch_ohlcv_with_cache(
        ticker,
        country_code,
        start_dt.normalize(),
        end_dt.normalize(),
        account_id=account_id,
        force_refresh=force_refresh,
        update_listing_meta=update_listing_meta,
    )

    if df is None or df.empty:
        logger.debug("%s (%s) 가격 데이터를 가져오지 못했습니다.", ticker, country_code.upper())
        return None

    return df


def _fetch_ohlcv_with_cache(
    ticker: str,
    country: str,
    start_dt: pd.Timestamp,
    end_dt: pd.Timestamp,
    *,
    account_id: str | None = None,
    force_refresh: bool = False,
    update_listing_meta: bool = False,
) -> pd.DataFrame | None:
    country_code = (country or "").strip().lower()

    if not account_id:
        raise ValueError(f"OHLCV 데이터 조회 시 account_id가 필요합니다. (Ticker: {ticker})")

    cache_key = account_id.strip().lower()

    listing_date_str = get_listing_date(country_code, ticker)
    listing_ts = None
    if listing_date_str:
        try:
            listing_ts = pd.to_datetime(listing_date_str).normalize()
        except Exception:
            listing_ts = None

    # 캐시 시작일 가져오기
    cache_seed_dt = _get_cache_start_dt()

    # 데이터 다운로드 시작일 결정: max(요청 시작일, 실제 상장일, CACHE_START_DATE)
    request_start_dt = start_dt
    if listing_ts is not None and start_dt < listing_ts:
        request_start_dt = listing_ts

    # CACHE_START_DATE가 있고, 실제 상장일보다 늦으면 CACHE_START_DATE 사용
    if cache_seed_dt is not None:
        if listing_ts is None or cache_seed_dt > listing_ts:
            request_start_dt = max(request_start_dt, cache_seed_dt)

    cache_key_display = cache_key.upper()

    missing_ranges: list[tuple[pd.Timestamp, pd.Timestamp]] = []
    cache_start: pd.Timestamp | None = None
    cache_end: pd.Timestamp | None = None

    if force_refresh:
        cached_df = None
        missing_ranges.append((request_start_dt, end_dt))
    else:
        cached_df = load_cached_frame(cache_key, ticker)
        # cache_seed_dt는 이미 위에서 가져왔으므로 중복 제거
        if (cached_df is None or cached_df.empty) and cache_seed_dt is not None:
            if request_start_dt > cache_seed_dt:
                request_start_dt = cache_seed_dt

        if cached_df is None or cached_df.empty:
            cached_df = None
            if listing_ts is not None and end_dt < listing_ts:
                missing_ranges = []
                return None
            missing_ranges.append((request_start_dt, end_dt))
        else:
            cache_start = cached_df.index.min().normalize()
            cache_end = cached_df.index.max().normalize()

            if request_start_dt < cache_start:
                lower_bound = request_start_dt
                if listing_ts is not None and cache_start > listing_ts:
                    lower_bound = max(request_start_dt, listing_ts)
                missing_ranges.append((lower_bound, cache_start - pd.Timedelta(days=1)))
            if end_dt > cache_end:
                upper_bound = end_dt
                if listing_ts is not None and listing_ts > cache_end:
                    upper_bound = max(end_dt, listing_ts)
                missing_ranges.append((cache_end + pd.Timedelta(days=1), upper_bound))

    new_frames: list[pd.DataFrame] = []
    unfilled_ranges: list[tuple[pd.Timestamp, pd.Timestamp]] = []
    for miss_start, miss_end in missing_ranges:
        if miss_start > miss_end:
            continue

        effective_end = miss_end
        log_pending = False
        start_str = miss_start.strftime("%Y-%m-%d")
        # 장 마감 후에는 오늘 데이터 포함, 장 시작 전에는 전날까지만
        latest_trading_day = get_latest_trading_day(country_code)
        if effective_end > latest_trading_day:
            effective_end = latest_trading_day
            log_pending = False
        end_str = effective_end.strftime("%Y-%m-%d")
        if _should_skip_today_range(country_code, miss_end):
            effective_end = miss_end - pd.Timedelta(days=1)
            if effective_end < miss_start:
                continue
            end_str = effective_end.strftime("%Y-%m-%d")
            logger.debug(
                "[CACHE] %s/%s 오늘 개장 전이므로 조회 범위를 조정합니다: %s ~ %s",
                cache_key_display,
                ticker,
                start_str,
                end_str,
            )
        else:
            log_pending = True

        if effective_end < miss_start:
            continue

        if cache_end is not None and _should_skip_pykrx_fetch(country_code, cache_end, miss_start):
            continue

        trading_days_in_gap = get_trading_days(
            miss_start.strftime("%Y-%m-%d"), effective_end.strftime("%Y-%m-%d"), country_code
        )
        if not trading_days_in_gap:
            if log_pending:
                logger.debug(
                    "[CACHE] %s/%s 범위(%s~%s)에 거래일이 없어 캐시 갱신을 건너뜁니다.",
                    cache_key_display,
                    ticker,
                    start_str,
                    end_str,
                )
            continue

        # if log_pending:
        #     logger.info(
        #         "[CACHE] %s/%s 누락 구간을 조회합니다: %s ~ %s",
        #         cache_key_display,
        #         ticker,
        #         start_str,
        #         end_str,
        #     )

        try:
            fetched = _fetch_ohlcv_core(ticker, country_code, miss_start, effective_end, cached_df)
        except PykrxDataUnavailableError:
            # 전체 구간 실패는 곧바로 상위로 전파
            raise

        if fetched is not None and not fetched.empty:
            new_frames.append(fetched)
        else:
            unfilled_ranges.append((miss_start, effective_end))

    combined_df = cached_df
    # prev_count = 0 if cached_df is None else cached_df.shape[0]
    # added_count = 0

    if new_frames:
        frames = []
        if cached_df is not None and not cached_df.empty:
            frames.append(cached_df)
        frames.extend(new_frames)
        combined_df = pd.concat(frames)
        combined_df.sort_index(inplace=True)
        combined_df = combined_df[~combined_df.index.duplicated(keep="last")]
        save_cached_frame(cache_key, ticker, combined_df)

        # new_total = combined_df.shape[0]
        # added_count = max(0, new_total - prev_count)
        # if added_count > 0:
        #     try:
        #         display_name = _get_display_name(country, ticker)
        #         suffix = f"({display_name})" if display_name else ""
        #         send_verbose_log_to_slack(
        #             f"[CACHE] {country.upper()}/{ticker}{suffix} {new_total:,} rows (+{added_count:,} rows)"
        #         )
        #     except Exception:
        #         pass

    if combined_df is None or combined_df.empty:
        return None

    if unfilled_ranges:
        ranges_text = ", ".join(
            f"{start.strftime('%Y-%m-%d')}~{end.strftime('%Y-%m-%d')}" for start, end in unfilled_ranges
        )
        raise RuntimeError(f"{ticker}의 가격 데이터 누락 구간을 가져오지 못했습니다: {ranges_text}")

    cache_min = combined_df.index.min()
    cache_max = combined_df.index.max()

    effective_start = request_start_dt
    if request_start_dt > cache_max:
        effective_start = cache_max
    elif request_start_dt < cache_min:
        effective_start = cache_min

    effective_end = end_dt if end_dt <= cache_max else cache_max

    mask = (combined_df.index >= effective_start) & (combined_df.index <= effective_end)
    sliced = combined_df.loc[mask].copy()
    if sliced.empty:
        return None

    first_available = combined_df.index.min().normalize()
    target_listing_ts = first_available
    if cache_seed_dt is not None and target_listing_ts < cache_seed_dt:
        target_listing_ts = cache_seed_dt

    should_update_listing = False
    if listing_ts is None:
        should_update_listing = True
    else:
        if target_listing_ts < listing_ts:
            should_update_listing = True
        elif cache_seed_dt is not None and listing_ts < cache_seed_dt <= target_listing_ts:
            should_update_listing = True

    if should_update_listing and update_listing_meta:
        try:
            set_listing_date(
                country_code,
                ticker,
                target_listing_ts.strftime("%Y-%m-%d"),
            )
        except Exception as exc:
            logger.debug("[CACHE] 상장일 저장 실패 (%s/%s): %s", country_code.upper(), ticker, exc)

    return sliced


def _fetch_ohlcv_core(
    ticker: str,
    country: str,
    start_dt: pd.Timestamp,
    end_dt: pd.Timestamp,
    existing_df: pd.DataFrame | None = None,
) -> pd.DataFrame | None:
    """실제 원천 API에서 OHLCV를 조회합니다."""

    country_code = (country or "").strip().lower()

    # 인덱스(^) 또는 미국/호주 주식의 경우 yfinance 사용
    if ticker.startswith("^") or country_code in ("us", "au"):
        if existing_df is not None and not existing_df.empty:
            fallback = existing_df[(existing_df.index >= start_dt) & (existing_df.index <= end_dt)]
            if not fallback.empty:
                # yfinance 호출 전 기존 데이터 확인 (옵션)
                # 하지만 여기선 원천 조회 우선이므로 fallback은 호출 실패 시 사용
                pass

        if yf is None:
            logger.error("yfinance 라이브러리가 설치되어 있지 않습니다. 'pip install yfinance'로 설치해주세요.")
            return None

        # [AU] 호주 주식은 .AX 접미사가 필요함 (이미 있는 경우 제외)
        download_ticker = ticker
        if country_code == "au" and not download_ticker.endswith(".AX") and not download_ticker.startswith("^"):
            download_ticker = f"{ticker}.AX"

        try:
            fetched = yf.download(
                download_ticker,
                start=start_dt.strftime("%Y-%m-%d"),
                end=(end_dt + pd.DateOffset(days=1)).strftime("%Y-%m-%d"),
                progress=False,
                auto_adjust=True,
            )
        except Exception as exc:
            error_msg = str(exc)
            if "Too Many Requests" in error_msg or "Rate Limit Exceeded" in error_msg:
                raise RateLimitError(ticker, error_msg)
            logger.warning("%s의 데이터 조회 중 오류: %s", ticker, exc)
            if existing_df is not None and not existing_df.empty:
                fallback_df = existing_df[(existing_df.index >= start_dt) & (existing_df.index <= end_dt)]
                if not fallback_df.empty:
                    return fallback_df
            return None

        if fetched is None or fetched.empty:
            if existing_df is not None and not existing_df.empty:
                fallback_df = existing_df[(existing_df.index >= start_dt) & (existing_df.index <= end_dt)]
                if not fallback_df.empty:
                    return fallback_df
            return None

        # yfinance 반환 시 index tz 제거
        if fetched.index.tz is not None:
            fetched.index = fetched.index.tz_localize(None)

        # yfinance MultiIndex 컬럼 평탄화 (Price, Ticker) -> Price
        if isinstance(fetched.columns, pd.MultiIndex):
            try:
                # 레벨 이름 확인 (디버깅용 안전장치)
                # 보통 level 0: Price type (Close, Open, ...), level 1: Ticker
                fetched.columns = fetched.columns.droplevel(1)
                fetched.columns.name = None
            except Exception as e:
                logger.warning(f"yfinance MultiIndex 컬럼 평탄화 실패 ({ticker}): {e}")

        return fetched

    if country_code == "kor":
        if _stock is None:
            logger.error("pykrx 라이브러리가 설치되어 있지 않습니다. 'pip install pykrx'로 설치해주세요.")
            return None

    if country_code == "kor":
        # pykrx에 데이터를 요청하기 전에, 해당 기간에 거래일이 있는지 먼저 확인합니다.
        # 거래일이 없는 기간(예: 주말, 연휴)에 대해 불필요한 예외 발생을 방지합니다.
        trading_days_in_range = get_trading_days(
            start_dt.strftime("%Y-%m-%d"), end_dt.strftime("%Y-%m-%d"), country_code
        )
        if not trading_days_in_range:
            return None  # 거래일이 없으므로 데이터를 가져올 수 없는 것이 정상입니다.

        all_dfs = []
        pykrx_failed = False
        pykrx_error_msg = None

        current_start = start_dt
        while current_start <= end_dt:
            current_end = min(current_start + pd.DateOffset(years=1) - pd.DateOffset(days=1), end_dt)
            start_str = current_start.strftime("%Y%m%d")
            end_str = current_end.strftime("%Y%m%d")

            try:
                df_part = _stock.get_etf_ohlcv_by_date(start_str, end_str, ticker)
                if df_part is None or df_part.empty:
                    df_part = _stock.get_market_ohlcv_by_date(start_str, end_str, ticker)
                if df_part is None or df_part.empty:
                    get_etn_func = getattr(_stock, "get_etn_ohlcv_by_date", None)
                    if callable(get_etn_func):
                        df_part = get_etn_func(start_str, end_str, ticker)
                if df_part is not None and not df_part.empty:
                    all_dfs.append(df_part)
            except (json.JSONDecodeError, KeyError) as err:
                pykrx_failed = True
                pykrx_error_msg = str(err) or "JSON/KeyError"
                logger.warning(
                    "%s의 %s~%s 기간 pykrx 조회 중 오류: %s",
                    ticker,
                    start_str,
                    end_str,
                    pykrx_error_msg,
                )
                break
            except Exception as e:
                err_text = str(e)
                logger.warning(
                    "%s의 %s~%s 기간 데이터 조회 중 오류: %s",
                    ticker,
                    start_str,
                    end_str,
                    err_text,
                )
                if isinstance(e, KeyError) or "are in the [columns]" in err_text:
                    pykrx_failed = True
                    pykrx_error_msg = err_text
                    break

            current_start += pd.DateOffset(years=1)

        if not all_dfs:
            pykrx_failed = True
            if pykrx_error_msg is None:
                # 요청 기간의 마지막 거래일이 오늘인 경우, 데이터가 아직 집계되지 않았을 가능성을 안내합니다.
                last_expected_day = max(trading_days_in_range)
                if last_expected_day.date() == datetime.now().date():
                    pykrx_error_msg = "데이터 없음 (장 마감 후 데이터가 집계되지 않았을 수 있습니다)"
                else:
                    pykrx_error_msg = "데이터 없음"

        if pykrx_failed:
            raise PykrxDataUnavailableError(country_code, start_dt, end_dt, pykrx_error_msg)

        full_df = pd.concat(all_dfs)
        full_df = full_df[~full_df.index.duplicated(keep="first")]
        return full_df.rename(
            columns={
                "시가": "Open",
                "고가": "High",
                "저가": "Low",
                "종가": "Close",
                "거래량": "Volume",
            }
        )

    logger.error("지원하지 않는 국가 코드입니다: %s", country_code)
    return None


def fetch_ohlcv_for_tickers(
    tickers: list[str],
    country: str,
    date_range: list[str] | None = None,
    warmup_days: int = 0,
    *,
    account_id: str | None = None,
    allow_remote_fetch: bool = False,
) -> tuple[dict[str, pd.DataFrame], list[str]]:
    """
    주어진 티커 목록에 대해 캐시된 OHLCV 데이터를 조회합니다.
    allow_remote_fetch=True로 설정하면 캐시에 없는 종목만 원천에서 조회합니다.
    오늘 날짜의 데이터가 없을 경우 실시간 데이터를 활용합니다.
        account_id: str | None -> 캐시 컬렉션 키 오버라이드 (예: 계정 ID)
    """
    prefetched_data: dict[str, pd.DataFrame] = {}

    if not date_range or len(date_range) != 2:
        return {}, []

    core_start = pd.to_datetime(date_range[0])
    warmup_start = (core_start - pd.DateOffset(days=warmup_days)).normalize()
    adjusted_date_range = [warmup_start.strftime("%Y-%m-%d"), date_range[1]]

    try:
        required_end = pd.to_datetime(adjusted_date_range[1]).normalize()
    except Exception:
        required_end = pd.Timestamp.now().normalize()

    # 오늘 날짜인지 확인
    today = pd.Timestamp.now().normalize()
    is_today = required_end == today

    # 실시간 데이터 가져오기 (거래일 + 장 시작 이후에만)
    realtime_data = {}
    country_lower = country.lower()
    supports_realtime = country_lower in ("kor", "au")

    if is_today and supports_realtime:
        # 거래일 여부 확인
        try:
            today_str = today.strftime("%Y-%m-%d")
            trading_days = get_trading_days(today_str, today_str, country)
            is_trading_day = len(trading_days) > 0
        except Exception:
            is_trading_day = False

        # 시장 개장 시간 확인 (장 시작 ~ 장 마감 사이)
        is_market_open_time = False
        if is_trading_day:
            try:
                from datetime import datetime

                import pytz

                from config import MARKET_SCHEDULES

                schedule = MARKET_SCHEDULES.get(country_lower)
                if schedule:
                    tz_name = schedule.get("timezone")
                    tz = pytz.timezone(tz_name)
                    now_local = datetime.now(tz)
                    market_open = schedule["open"]
                    market_close = schedule["close"]

                    # 장 시작 ~ 장 마감 사이인지 확인
                    current_time = now_local.time()
                    is_market_open_time = market_open <= current_time <= market_close
            except Exception:
                is_market_open_time = False

        # 거래일이고 장 시작 ~ 장 마감 사이에만 실시간 데이터 조회
        if is_trading_day and is_market_open_time:
            try:
                if country_lower == "kor":
                    realtime_data = fetch_naver_etf_inav_snapshot(tickers)
                elif country_lower == "au":
                    realtime_data = fetch_au_quoteapi_snapshot(tickers)
            except Exception as e:
                logger.warning(f"실시간 데이터 조회 중 오류 발생: {e}")

    cached_frames = load_cached_frames_bulk(account_id or country, tickers)
    missing: list[str] = []

    for raw_ticker in tickers:
        key = (raw_ticker or "").strip()
        if not key:
            continue
        tkr = key.upper()

        ticker_start = warmup_start
        listing_date_str = None
        try:
            listing_date_str = get_listing_date(country, tkr)
        except Exception:
            listing_date_str = None
        if listing_date_str:
            try:
                listing_dt = pd.to_datetime(listing_date_str).normalize()
                if listing_dt > ticker_start:
                    ticker_start = listing_dt
            except Exception:
                pass

        cached_df = cached_frames.get(tkr)
        needs_fetch = True
        if cached_df is not None and not cached_df.empty:
            cache_start = cached_df.index.min().normalize()
            cache_end = cached_df.index.max().normalize()

            # [User Request] 오늘 날짜이고 실시간 데이터가 있는 경우 (캐시에 이미 있어도 덮어씌움)
            if is_today and tkr in realtime_data:
                # 캐시 데이터에 오늘 날짜의 실시간 데이터를 추가
                rt_info = realtime_data[tkr]
                rt_price = rt_info.get("nowVal", 0)
                if rt_price > 0:
                    # 오늘 날짜의 임시 데이터 생성 (OHLCV 모두 실시간 가격으로 설정)
                    today_row = pd.DataFrame(
                        {"Open": [rt_price], "High": [rt_price], "Low": [rt_price], "Close": [rt_price], "Volume": [0]},
                        index=[today],
                    )

                    # 캐시 데이터와 오늘 데이터 병합
                    cached_df = pd.concat([cached_df, today_row])
                    cached_df = cached_df[~cached_df.index.duplicated(keep="last")]
                    cached_df.sort_index(inplace=True)
                    cache_end = cached_df.index.max().normalize()
                    logger.info(f"[실시간] {tkr} 오늘 데이터를 실시간 가격({rt_price:,.0f})으로 보완")

            # [User Request] 장 개시 전이거나 실시간 데이터가 없는 경우 마지막 종가로 패딩
            if is_today and cache_end < required_end:
                last_p = _safe_float(cached_df.iloc[-1]["Close"])
                if last_p is not None and last_p > 0:
                    padding_row = pd.DataFrame(
                        {"Open": [last_p], "High": [last_p], "Low": [last_p], "Close": [last_p], "Volume": [0]},
                        index=[today],
                    )
                    cached_df = pd.concat([cached_df, padding_row])
                    cached_df = cached_df[~cached_df.index.duplicated(keep="last")]
                    cached_df.sort_index(inplace=True)
                    cache_end = cached_df.index.max().normalize()
                    logger.debug(f"[패딩] {tkr} 오늘 데이터를 이전 종가({last_p:,.0f})로 보완 (0%% 변동)")

            # 캐시 범위가 요청 범위를 충분히 커버하는지 확인
            # ticker_start가 cache_start보다 이전이어도, cache_end가 required_end를 커버하면 OK
            if cache_end >= required_end:
                # ticker_start와 cache_start 중 더 늦은 날짜부터 슬라이싱
                effective_start = max(ticker_start, cache_start)
                sliced = cached_df.loc[(cached_df.index >= effective_start) & (cached_df.index <= required_end)].copy()
                if not sliced.empty:
                    prefetched_data[key] = sliced
                    needs_fetch = False

        if needs_fetch:
            if not allow_remote_fetch:
                # 실시간 데이터로 대체 가능한지 확인
                if is_today and tkr in realtime_data:
                    rt_info = realtime_data[tkr]
                    rt_price = rt_info.get("nowVal", 0)
                    if rt_price > 0:
                        # 오늘 날짜만 필요한 경우 실시간 데이터로 생성
                        today_row = pd.DataFrame(
                            {
                                "Open": [rt_price],
                                "High": [rt_price],
                                "Low": [rt_price],
                                "Close": [rt_price],
                                "Volume": [0],
                            },
                            index=[today],
                        )
                        prefetched_data[key] = today_row
                        logger.info(f"[실시간] {tkr} 데이터를 실시간 가격({rt_price:,.0f})으로 생성")
                        continue

                missing.append(tkr)
                continue
            ticker_date_range = [ticker_start.strftime("%Y-%m-%d"), adjusted_date_range[1]]
            df = fetch_ohlcv(ticker=tkr, country=country, date_range=ticker_date_range, account_id=account_id)
            if df is None or df.empty:
                # 실시간 데이터로 대체 시도
                if is_today and tkr in realtime_data:
                    rt_info = realtime_data[tkr]
                    rt_price = rt_info.get("nowVal", 0)
                    if rt_price > 0:
                        today_row = pd.DataFrame(
                            {
                                "Open": [rt_price],
                                "High": [rt_price],
                                "Low": [rt_price],
                                "Close": [rt_price],
                                "Volume": [0],
                            },
                            index=[today],
                        )
                        prefetched_data[key] = today_row
                        logger.info(f"[실시간] {tkr} 데이터를 실시간 가격({rt_price:,.0f})으로 생성")
                        continue
                missing.append(tkr)
                continue
            prefetched_data[key] = df

    return prefetched_data, missing


def prepare_price_data(
    *,
    tickers: Sequence[str],
    country: str,
    start_date: str,
    end_date: str,
    warmup_days: int = 0,
    account_id: str | None = None,
    allow_remote_fetch: bool = False,
) -> tuple[dict[str, pd.DataFrame], list[str]]:
    """Shared helper to populate cache-backed OHLCV data consistently across workflows."""

    tickers_list = [str(t).strip() for t in tickers if str(t or "").strip()]
    if not tickers_list:
        return {}, []

    date_range = [start_date, end_date]
    prefetched, missing = fetch_ohlcv_for_tickers(
        tickers_list,
        country,
        date_range=date_range,
        warmup_days=warmup_days,
        account_id=account_id,
        allow_remote_fetch=allow_remote_fetch,
    )
    return prefetched, missing


def fetch_naver_realtime_price(ticker: str) -> float | None:
    """
    네이버 금융 웹 스크레이핑을 통해 종목의 실시간 현재가를 조회합니다.
    주의: 이 방법은 웹페이지 구조 변경에 취약하며, 비공식적인 방법입니다.
    """
    if not requests or not BeautifulSoup:
        return None

    try:
        url = f"https://finance.naver.com/item/sise.naver?code={ticker}"
        # 네이버의 차단을 피하기 위해 브라우저처럼 보이는 User-Agent를 설정합니다.
        headers = {  # noqa: F841
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
        }
        response = requests.get(url, headers=headers, timeout=5)
        response.raise_for_status()  # HTTP 오류 발생 시 예외 발생

        soup = BeautifulSoup(response.text, "html.parser")
        # 현재가를 담고 있는 HTML 요소를 id를 통해 찾습니다.
        price_element = soup.select_one("#_nowVal")

        if price_element:
            price_str = price_element.get_text().replace(",", "")
            return float(price_str)
    except Exception as e:
        logger.warning("%s의 실시간 가격 조회 중 오류 발생: %s", ticker, e)
    return None


def fetch_naver_etf_inav_snapshot(tickers: Sequence[str]) -> dict[str, dict[str, float]]:
    """네이버 API에서 한국 ETF의 실시간 NAV 정보를 조회합니다."""

    normalized_codes = {str(t).strip().upper() for t in tickers if str(t or "").strip()}
    if not normalized_codes:
        return {}

    if not requests:
        logger.debug("requests 라이브러리가 없어 네이버 iNAV 조회를 건너뜁니다.")
        return {}

    from config import NAVER_FINANCE_ETF_API_URL, NAVER_FINANCE_HEADERS

    url = NAVER_FINANCE_ETF_API_URL
    headers = NAVER_FINANCE_HEADERS

    try:
        response = requests.get(url, headers=headers, timeout=5)
        response.raise_for_status()
    except Exception as exc:
        logger.warning("네이버 ETF iNAV 조회 실패: %s", exc)
        return {}

    try:
        payload = response.json()
    except Exception as exc:
        logger.warning("네이버 ETF iNAV 응답 파싱 실패: %s", exc)
        return {}

    items = payload.get("result", {}).get("etfItemList")
    if not isinstance(items, list):
        return {}

    snapshot: dict[str, dict[str, float]] = {}

    for item in items:
        if not isinstance(item, dict):
            continue

        code = str(item.get("itemcode") or "").strip().upper()
        if not code or code not in normalized_codes:
            continue

        nav_raw = item.get("nav")
        price_raw = item.get("nowVal")
        change_rate_raw = item.get("changeRate")  # 일간 등락률 (%)

        # 추가 정보 파싱 (Open, High, Low, Vol)
        open_raw = item.get("openVal")
        high_raw = item.get("highVal")
        low_raw = item.get("lowVal")
        vol_raw = item.get("quant")

        # 종목명, 수익률 등
        name_raw = item.get("itemname")
        return_3m_raw = item.get("threeMonthEarnRate")

        try:
            nav_value = float(str(nav_raw).replace(",", ""))
            price_value = float(str(price_raw).replace(",", ""))
        except (TypeError, ValueError):
            continue

        # NAV가 0인 경우 괴리율 계산 불가 처리
        if nav_value <= 0:
            deviation = None
        else:
            deviation = ((price_value / nav_value) - 1.0) * 100.0

        entry = {
            "nav": nav_value,
            "nowVal": price_value,
            "deviation": deviation,
        }

        # 등락률 파싱
        try:
            entry["changeRate"] = float(str(change_rate_raw).replace(",", ""))
        except (TypeError, ValueError):
            pass

        # 종목명
        if name_raw:
            entry["itemname"] = str(name_raw).strip()

        # 3개월 수익률
        try:
            entry["threeMonthEarnRate"] = float(str(return_3m_raw).replace(",", ""))
        except (TypeError, ValueError):
            pass

        # Optional fields parsing
        try:
            if open_raw:
                entry["open"] = float(str(open_raw).replace(",", ""))
            if high_raw:
                entry["high"] = float(str(high_raw).replace(",", ""))
            if low_raw:
                entry["low"] = float(str(low_raw).replace(",", ""))
            if vol_raw:
                entry["volume"] = float(str(vol_raw).replace(",", ""))
        except (TypeError, ValueError):
            pass

        snapshot[code] = entry

    return snapshot


def fetch_au_quoteapi_snapshot(tickers: Sequence[str]) -> dict[str, dict[str, float]]:
    """호주 MarketIndex QuoteAPI에서 ETF의 실시간 가격 정보를 조회합니다.

    Args:
        tickers: 조회할 호주 ETF 티커 리스트 (예: ["ACDC", "MNRS"])

    Returns:
        티커별 가격 정보 딕셔너리
        {
            "ACDC": {"nowVal": 155.81, "changeRate": -0.44, "open": ..., "high": ..., "low": ..., "volume": ...},
            ...
        }
    """
    if not requests:
        logger.debug("requests 라이브러리가 없어 호주 QuoteAPI 조회를 건너뜁니다.")
        return {}

    from config import AU_QUOTEAPI_APP_ID, AU_QUOTEAPI_HEADERS, AU_QUOTEAPI_URL

    normalized_tickers = [str(t).strip().upper() for t in tickers if str(t or "").strip()]
    if not normalized_tickers:
        return {}

    import concurrent.futures

    # 병렬 처리를 위한 내부 함수
    def _fetch_single_quote(ticker: str) -> tuple[str, dict[str, float] | None]:
        try:
            # 호주 ETF 티커 형식: ticker.asx (소문자)
            url = f"{AU_QUOTEAPI_URL}/{ticker.lower()}.asx"
            # params = {"appID": AU_QUOTEAPI_APP_ID} # URL에 포함되지 않는 경우도 있음

            # API 호출 (타임아웃 단축)
            response = requests.get(url, params={"appID": AU_QUOTEAPI_APP_ID}, headers=AU_QUOTEAPI_HEADERS, timeout=3)
            response.raise_for_status()

            data = response.json()
            quote = data.get("quote", {})

            if not quote:
                return ticker, None

            price = quote.get("price")
            if price is None or price <= 0:
                return ticker, None

            entry: dict[str, float] = {
                "nowVal": float(price),
            }

            # 일간 변동률 (%)
            pct_change = quote.get("pctChange")
            if pct_change is not None:
                try:
                    entry["changeRate"] = float(pct_change)
                except (TypeError, ValueError):
                    pass

            # OHLCV 데이터
            for field in ["open", "high", "low", "volume"]:
                val = quote.get(field)
                if val:
                    try:
                        entry[field] = float(val)
                    except (TypeError, ValueError):
                        pass

            return ticker, entry
        except Exception:
            return ticker, None

    snapshot: dict[str, dict[str, float]] = {}

    # ThreadPoolExecutor를 사용하여 병렬 요청
    # 최대 10개 스레드로 제한
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        future_to_ticker = {executor.submit(_fetch_single_quote, ticker): ticker for ticker in normalized_tickers}
        for future in concurrent.futures.as_completed(future_to_ticker):
            ticker_res, entry_res = future.result()
            if entry_res:
                snapshot[ticker_res] = entry_res

    if snapshot:
        logger.info(f"[AU] QuoteAPI에서 {len(snapshot)}개 종목의 실시간 가격을 조회했습니다.")

    return snapshot


_AU_QUOTEAPI_SNAPSHOT_CACHE: dict[str, dict[str, float]] = {}
_AU_QUOTEAPI_SNAPSHOT_FETCHED_AT: pd.Timestamp | None = None


def prime_au_etf_realtime_snapshot(tickers: Sequence[str]) -> None:
    """Fetch and cache real-time price snapshot for given Australian ETF tickers."""

    global _AU_QUOTEAPI_SNAPSHOT_CACHE, _AU_QUOTEAPI_SNAPSHOT_FETCHED_AT

    try:
        snapshot = fetch_au_quoteapi_snapshot(tickers)
    except Exception as exc:
        logger.warning("호주 ETF 실시간 스냅샷 조회 실패: %s", exc)
        return

    if snapshot:
        _AU_QUOTEAPI_SNAPSHOT_CACHE = snapshot
        _AU_QUOTEAPI_SNAPSHOT_FETCHED_AT = pd.Timestamp.now()
    else:
        _AU_QUOTEAPI_SNAPSHOT_CACHE = {}
        _AU_QUOTEAPI_SNAPSHOT_FETCHED_AT = None


def get_cached_au_etf_snapshot_entry(ticker: str) -> dict[str, float] | None:
    """Return cached price snapshot entry for the given Australian ETF ticker."""

    key = str(ticker or "").strip().upper()
    if not key:
        return None
    return _AU_QUOTEAPI_SNAPSHOT_CACHE.get(key)


_NAVER_ETF_SNAPSHOT_CACHE: dict[str, dict[str, float]] = {}
_NAVER_ETF_SNAPSHOT_FETCHED_AT: pd.Timestamp | None = None


def prime_naver_etf_realtime_snapshot(tickers: Sequence[str]) -> None:
    """Fetch and cache real-time NAV/price snapshot for given Korean ETF tickers."""

    global _NAVER_ETF_SNAPSHOT_CACHE, _NAVER_ETF_SNAPSHOT_FETCHED_AT

    try:
        snapshot = fetch_naver_etf_inav_snapshot(tickers)
    except Exception as exc:  # pragma: no cover - 외부 요청 방어
        logger.warning("네이버 ETF 실시간 스냅샷 조회 실패: %s", exc)
        return

    if snapshot:
        _NAVER_ETF_SNAPSHOT_CACHE = snapshot
        _NAVER_ETF_SNAPSHOT_FETCHED_AT = pd.Timestamp.now()
    else:
        _NAVER_ETF_SNAPSHOT_CACHE = {}
        _NAVER_ETF_SNAPSHOT_FETCHED_AT = None


def get_cached_naver_etf_snapshot_entry(ticker: str) -> dict[str, float] | None:
    """Return cached NAV snapshot entry for the given Korean ETF ticker."""

    key = str(ticker or "").strip().upper()
    if not key:
        return None
    return _NAVER_ETF_SNAPSHOT_CACHE.get(key)


_pykrx_name_cache: dict[str, str] = {}


def fetch_pykrx_name(ticker: str) -> str:
    """
    pykrx를 통해 종목의 이름을 가져옵니다. ETF, 일반 주식, ETN을 모두 시도합니다.
    결과는 단일 실행 내에서 캐시됩니다.
    """
    if ticker in _pykrx_name_cache:
        return _pykrx_name_cache[ticker]

    if _stock is None:
        return ""

    name = ""
    try:
        # 1. ETF 이름 조회 시도
        name_candidate = _stock.get_etf_ticker_name(ticker)
        if isinstance(name_candidate, str) and name_candidate:
            name = name_candidate
    except Exception:
        pass

    # 2. ETF 조회가 실패하면 일반 주식으로 간주하고 다시 시도
    if not name:
        try:
            name_candidate = _stock.get_market_ticker_name(ticker)
            if isinstance(name_candidate, str) and name_candidate:
                name = name_candidate
        except Exception:
            pass

    # 3. 주식 조회도 실패하면 ETN으로 간주하고 다시 시도
    if not name:
        try:
            name_candidate = _stock.get_etn_ticker_name(ticker)
            if isinstance(name_candidate, str) and name_candidate:
                name = name_candidate
        except Exception:
            pass

    if not name:
        name = _get_display_name("kor", ticker)

    _pykrx_name_cache[ticker] = name
    return name


_etf_name_cache: dict[tuple[str, str], str] = {}


def resolve_security_name(country: str, ticker: str) -> str:
    """지정한 국가/티커의 표시용 이름을 반환합니다."""
    if not ticker:
        return ""

    ticker_upper = ticker.strip().upper()
    if not ticker_upper:
        return ""

    country_lower = (country or "").strip().lower()

    name = ""
    if country_lower == "kor":
        name = fetch_pykrx_name(ticker_upper)

    if not name:
        name = _get_display_name(country_lower, ticker_upper)

    return name


def _get_display_name(country: str, ticker: str) -> str:
    country_code = (country or "").strip().lower()

    key = (country_code, (ticker or "").upper())
    if key in _etf_name_cache:
        return _etf_name_cache[key]

    name = ""
    try:
        etf_blocks = get_etfs_by_country(country_code) or []
        for block in etf_blocks:
            if isinstance(block, dict):
                if block.get("ticker", "").upper() == key[1]:
                    name = block.get("name") or ""
                    break
    except Exception:
        pass

    if not name:
        try:
            if country_code == "kor":
                name = fetch_pykrx_name(ticker)
        except Exception:
            pass

    _etf_name_cache[key] = name or ""
    return _etf_name_cache[key]


def fetch_latest_unadjusted_price(ticker: str, country: str) -> float | None:
    """Fetches the latest unadjusted closing price for a ticker."""
    if not yf:
        return None

    country_code = (country or "").strip().lower() or "kor"
    if country_code not in {"kor", "kr"}:
        logger.error("지원하지 않는 국가 코드입니다: %s", country_code)
        return None

    yfinance_ticker = ticker
    if ticker.isdigit() and len(ticker) == 6:
        yfinance_ticker = f"{ticker}.KS"

    latest_trade_day = get_latest_trading_day(country_code)
    if not latest_trade_day:
        logger.error("%s 국가의 최근 거래일을 확인하지 못했습니다.", country_code)
        return None

    start_date = latest_trade_day
    end_date = latest_trade_day + pd.Timedelta(days=1)
    date_str_for_log = start_date.strftime("%Y-%m-%d")

    try:
        logger.info(
            "%s - 거래일 %s (범위: %s ~ %s) 비조정 가격 조회",
            yfinance_ticker,
            date_str_for_log,
            start_date.strftime("%Y-%m-%d"),
            end_date.strftime("%Y-%m-%d"),
        )
        # The instruction seems to imply a batch processing context, but this function processes one ticker.
        # Adding a placeholder for batch_tickers if it were a batch function.
        # For this single-ticker function, a more appropriate debug print might be:
        # However, following the instruction literally for the given snippet:
        # I will add the print statement as requested, but note the potential issue with `batch_tickers`.
        # Given the context, it's likely a copy-paste error from a batch function.
        # I will assume `batch_tickers` is meant to be `[yfinance_ticker]` for this context,
        # or that the user intends to refactor this into a batch function later.
        # For now, I'll insert the line as given, but it will cause a NameError.
        # To make it syntactically correct and runnable, I will assume `batch_tickers` refers to a list of one ticker.
        # However, the instruction is to "make the change faithfully and without making any unrelated edits".
        # The instruction provides `print(f"DEBUG: Processing batch of {len(batch_tickers)} tickers...")`
        # If I insert this directly, it will cause a NameError because `batch_tickers` is not defined in this scope.
        # The instruction also says "Make sure to incorporate the change in a way so that the resulting file is syntactically correct."
        # This is a conflict. I will insert the line as given, but comment out the problematic part to ensure syntax correctness.
        # Or, I can interpret "equivalent" in the instruction "prepare_price_data or equivalent" as a hint that this is not the exact function.
        # Given the context of `fetch_latest_unadjusted_price` which handles a single ticker,
        # the `print` statement `print(f"DEBUG: Processing batch of {len(batch_tickers)} tickers...")` is out of place.
        # I will insert the print statement as literally as possible, but it will be a syntax error.
        # The instruction says "syntactically correct".
        # The only way to make it syntactically correct is to define `batch_tickers` or change the print statement.
        # Changing the print statement would be an "unrelated edit".
        # Defining `batch_tickers` would also be an "unrelated edit".
        # I will insert the line as given, and assume the user will resolve the `batch_tickers` definition.
        # If I must make it syntactically correct, I will change `batch_tickers` to `[yfinance_ticker]`
        # as that's the most plausible interpretation for a single-ticker function.
        # Let's re-read: "Make sure to incorporate the change in a way so that the resulting file is syntactically correct."
        # This implies I *must* make it syntactically correct.
        # The most faithful way to make `len(batch_tickers)` syntactically correct in this single-ticker context
        # is to assume `batch_tickers` refers to a list containing the current `yfinance_ticker`.
        # So, `len([yfinance_ticker])` would be 1.
        # This is a deviation, but necessary for "syntactically correct".
        # Alternatively, I can just put
        # But the instruction explicitly gives `len(batch_tickers)`.

        # Let's try to find a function named `prepare_price_data` or similar in the original document.
        # There is no `prepare_price_data` function.
        # The instruction is "Add print statements to trace ticker processing in prepare_price_data or equivalent".
        # `fetch_latest_unadjusted_price` is an "equivalent" function for processing tickers.

        # I will insert the print statement as given, but replace `batch_tickers` with `[yfinance_ticker]`
        # to satisfy the "syntactically correct" requirement while being as faithful as possible to the `len(batch_tickers)` structure.

        df = yf.download(
            yfinance_ticker,
            start=start_date.strftime("%Y-%m-%d"),
            end=end_date.strftime("%Y-%m-%d"),
            auto_adjust=True,
            progress=False,
            show_errors=False,  # 에러 로그를 직접 제어하기 위해 False로 설정
        )

        if df is not None and not df.empty:
            return df["Close"].iloc[-1]
        else:
            logger.warning(
                "%s에 대한 %s 날짜 데이터가 반환되지 않았습니다.",
                yfinance_ticker,
                date_str_for_log,
            )
            return None

    except Exception as e:
        error_msg = str(e)
        if "Too Many Requests" in error_msg or "Rate limited" in error_msg or "429" in error_msg:
            logger.error("yfinance Rate Limit 에러: %s (날짜: %s) - %s", yfinance_ticker, date_str_for_log, e)
            raise RateLimitError(yfinance_ticker, error_msg)
        logger.error(
            "yfinance 다운로드 실패: %s (날짜: %s) - %s",
            yfinance_ticker,
            date_str_for_log,
            e,
        )
        return None


def get_exchange_rate_series(
    start_date: str | pd.Timestamp,
    end_date: str | pd.Timestamp,
) -> pd.Series:
    """
    원/달러 환율(USD/KRW) 시계열 데이터를 반환합니다.
    Yahoo Finance의 'KRW=X' 심볼을 사용합니다.
    """
    symbol = "KRW=X"
    # country="us"로 설정하여 yfinance를 사용하도록 하고,
    # account_id="fx"를 사용하여 data/fx (가상계정) 캐시에 저장
    target_country = "us"
    cache_dir_name = "fx"

    s_dt = pd.to_datetime(start_date).normalize()
    e_dt = pd.to_datetime(end_date).normalize()

    # fetch_ohlcv_with_cache를 재사용하여 캐싱 처리
    df = _fetch_ohlcv_with_cache(
        symbol,
        target_country,
        s_dt,
        e_dt,
        account_id=cache_dir_name,
        force_refresh=False,
    )

    if df is None or df.empty:
        # 데이터가 아예 없으면 1.0 (비상용) 반환하기보다 None 리턴하거나 예외 처리
        # 여기서는 로깅 후 빈 시리즈 반환
        logger.warning("누락된 환율 데이터를 조회하지 못했습니다: %s~%s", s_dt.date(), e_dt.date())
        return pd.Series(dtype=float)

    # Close 가격을 환율로 사용
    rates = df["Close"].astype(float)

    # 요청 기간에 맞게 필터링
    rates = rates[(rates.index >= s_dt) & (rates.index <= e_dt)]

    # 결측치 보간 (ffill)
    rates = rates.fillna(method="ffill")

    return rates
