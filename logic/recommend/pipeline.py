"""êµ­ê°€ ê¸°ë°˜ ê°„ì†Œí™” ì¶”ì²œ íŒŒì´í”„ë¼ì¸."""

from __future__ import annotations

import json
import re
import time
from datetime import datetime, timedelta
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional

import pandas as pd

# ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
DATA_DIR = Path(__file__).parent.parent.parent / "data" / "stocks"
from utils.settings_loader import (
    AccountSettingsError,
    get_account_settings,
    get_strategy_rules,
    load_common_settings,
)
from strategies.maps.constants import DECISION_CONFIG, DECISION_MESSAGES, DECISION_NOTES
from logic.common import sort_decisions_by_order_and_score, filter_category_duplicates
from strategies.maps.history import (
    calculate_consecutive_holding_info,
    calculate_trade_cooldown_info,
)
from utils.stock_list_io import get_etfs
from utils.trade_store import list_open_positions
from utils.data_loader import (
    fetch_ohlcv,
    prepare_price_data,
    get_latest_trading_day,
    get_next_trading_day,
    count_trading_days,
)
from utils.db_manager import get_db_connection
from logic.recommend.market import get_market_regime_status_info
from utils.logger import get_app_logger

logger = get_app_logger()


@dataclass
class RecommendationReport:
    account_id: str
    country_code: str
    base_date: pd.Timestamp
    recommendations: List[Dict[str, Any]]
    report_date: datetime
    summary_data: Optional[Dict[str, Any]] = None
    header_line: Optional[str] = None
    detail_headers: Optional[List[str]] = None
    detail_rows: Optional[List[List[Any]]] = None
    detail_extra_lines: Optional[List[str]] = None
    decision_config: Dict[str, Any] = None


@dataclass
class _TickerMeta:
    ticker: str
    name: str
    category: str


@dataclass
class _TickerScore:
    meta: _TickerMeta
    price: float
    prev_close: float
    daily_pct: float
    score: float
    streak: int
    category: str
    ma_value: float = 0.0


def _load_full_etf_meta(country_code: str) -> Dict[str, Dict[str, Any]]:
    """Load metadata for all ETFs including recommend_disabled ones."""

    file_path = DATA_DIR / f"{country_code}.json"
    if not file_path.exists():
        return {}

    try:
        with file_path.open("r", encoding="utf-8") as f:
            data = json.load(f)
    except Exception as exc:
        logger.warning("ì „ì²´ ETF ë©”íƒ€ ë¡œë“œ ì‹¤íŒ¨: %s", exc)
        return {}

    meta_map: Dict[str, Dict[str, Any]] = {}
    if not isinstance(data, list):
        return meta_map

    for block in data:
        if not isinstance(block, dict):
            continue

        raw_category = block.get("category")
        if isinstance(raw_category, (list, set, tuple)):
            raw_category = next(iter(raw_category), "") if raw_category else ""
        category_name = str(raw_category or "TBD").strip() or "TBD"

        tickers = block.get("tickers") or []
        if not isinstance(tickers, list):
            continue

        for item in tickers:
            if not isinstance(item, dict):
                continue

            ticker = str(item.get("ticker") or "").strip().upper()
            if not ticker:
                continue

            raw_item_category = item.get("category", category_name)
            if isinstance(raw_item_category, (list, set, tuple)):
                raw_item_category = next(iter(raw_item_category), "") if raw_item_category else ""
            item_category = str(raw_item_category or category_name or "TBD").strip() or "TBD"

            name = str(item.get("name") or ticker).strip() or ticker

            meta_map[ticker] = {
                "ticker": ticker,
                "name": name,
                "category": item_category,
            }

    return meta_map


def _fetch_dataframe(
    ticker: str,
    *,
    country: str,
    ma_period: int,
    base_date: Optional[pd.Timestamp],
    prefetched_data: Optional[Dict[str, pd.DataFrame]] = None,
) -> Optional[pd.DataFrame]:
    try:
        if prefetched_data and ticker in prefetched_data:
            df = prefetched_data[ticker]
        else:
            months_back = max(12, ma_period)  # ìµœì†Œ 1ë…„ì¹˜ ë°ì´í„° ìš”ì²­
            df = fetch_ohlcv(
                ticker,
                country=country,
                months_back=months_back,
                base_date=base_date,
            )

        if df is None or df.empty:
            logger.warning("%sì— ëŒ€í•œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", ticker)
            return None

        if "Close" not in df.columns:
            logger.warning("%sì— ëŒ€í•œ ì¢…ê°€(Close) ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", ticker)
            return None

        df = df.dropna(subset=["Close"])

        if df.empty:
            logger.warning("%sì— ëŒ€í•œ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", ticker)
            return None

        return df

    except Exception as e:
        logger.warning("%s ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: %s", ticker, e)
        import traceback

        traceback.print_exc()
        return None


def _calc_metrics(df: pd.DataFrame, ma_period: int) -> Optional[tuple]:
    try:
        # 'Close' ë˜ëŠ” 'Adj Close' ì¤‘ ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ ì„ íƒ
        if "unadjusted_close" in df.columns:
            raw_close = df["unadjusted_close"].astype(float)
        else:
            raw_close = df["Close"].astype(float)

        if "Adj Close" in df.columns and not df["Adj Close"].isnull().all():
            price_series = df["Adj Close"].astype(float)
        else:
            price_series = raw_close

        raw_close = raw_close.dropna()
        price_series = price_series.dropna()

        if raw_close.empty or price_series.empty:
            return None

        # ì´ë™í‰ê·  ê³„ì‚° (ìµœì†Œ 1ê°œ ë°ì´í„°ë¡œë„ ê³„ì‚° ê°€ëŠ¥í•˜ë„ë¡ min_periods=1 ì„¤ì •)
        ma = price_series.rolling(window=ma_period, min_periods=1).mean()

        latest_close = float(price_series.iloc[-1])
        prev_close = float(price_series.iloc[-2]) if len(price_series) >= 2 else latest_close
        ma_value = float(ma.iloc[-1]) if not pd.isna(ma.iloc[-1]) else latest_close

        # 0 ì´í•˜ ê°’ì´ë©´ ê¸°ë³¸ê°’ ì„¤ì •
        if ma_value <= 0:
            ma_value = latest_close if latest_close > 0 else 1.0

        if latest_close <= 0:
            return None

        # ì¼ê°„ ìˆ˜ìµë¥  ê³„ì‚° (ì´ì „ ì¢…ê°€ê°€ ì—†ê±°ë‚˜ 0 ì´í•˜ë©´ 0%ë¡œ ì²˜ë¦¬)
        daily_pct = 0.0
        raw_prev_close = float(raw_close.iloc[-2]) if len(raw_close) >= 2 else float(raw_close.iloc[-1])
        raw_latest_close = float(raw_close.iloc[-1])
        if raw_prev_close and raw_prev_close > 0:
            daily_pct = ((raw_latest_close / raw_prev_close) - 1.0) * 100

        # ì ìˆ˜ ê³„ì‚° (ì´ë™í‰ê·  ëŒ€ë¹„ ìˆ˜ìµë¥ , % ë‹¨ìœ„)
        score = 0.0
        if ma_value > 0:
            score = ((latest_close / ma_value) - 1.0) * 100

        # ì ìˆ˜ê°€ ë§¤ìš° ì‘ìœ¼ë©´ 0.01%ë¡œ ì²˜ë¦¬ (0ì  ë°©ì§€)
        if abs(score) < 0.01 and score != 0:
            score = 0.01 if score > 0 else -0.01

        # ì—°ì† ìƒìŠ¹ì¼ ê³„ì‚°
        streak = 0
        for price, ma_entry in zip(reversed(price_series.iloc[-ma_period:]), reversed(ma.iloc[-ma_period:])):
            if pd.isna(ma_entry) or pd.isna(price) or price < ma_entry:
                break
            streak += 1

        # ë³´ìœ ì¼ ê³„ì‚° (ìµœëŒ€ 20ì¼ë¡œ ì œí•œ)
        holding_days = min(streak, 20) if streak > 0 else 0

        return latest_close, prev_close, daily_pct, score, holding_days
    except Exception as e:
        logger.exception("ë©”íŠ¸ë¦­ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: %s", e)
        return None


def _build_score(meta: _TickerMeta, metrics) -> _TickerScore:
    # ë©”íŠ¸ë¦­ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
    if metrics is None:
        logger.warning("%sì— ëŒ€í•œ ë©”íŠ¸ë¦­ì´ ì—†ìŠµë‹ˆë‹¤.", meta.ticker)
        return _TickerScore(
            meta=meta,
            price=0.0,
            prev_close=0.0,
            daily_pct=0.0,
            score=0.0,
            streak=0,
            category="",  # ì¹´í…Œê³ ë¦¬ë¥¼ ë¹ˆ ë¬¸ìì—´ë¡œ ì´ˆê¸°í™”
        )

    try:
        price, prev_close, daily_pct, score, holding_days = metrics

        # ì ìˆ˜ê°€ ë§¤ìš° ì‘ì€ ê²½ìš° 0ìœ¼ë¡œ ì²˜ë¦¬í•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
        if abs(score) < 0.01 and score != 0:
            score = 0.01 if score > 0 else -0.01

        # ì¹´í…Œê³ ë¦¬ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •
        category = ""
        if hasattr(meta, "category") and meta.category is not None:
            # ì¹´í…Œê³ ë¦¬ê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²« ë²ˆì§¸ í•­ëª©ì„ ì‚¬ìš©
            if isinstance(meta.category, (set, list)):
                category = str(next(iter(meta.category), "")) if meta.category else ""
            else:
                category = str(meta.category)

        # ì ìˆ˜ê°€ Noneì´ ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, Noneì´ë©´ 0.0ìœ¼ë¡œ ì„¤ì •
        final_score = float(round(score, 2)) if score is not None else 0.0

        # ì´ë™í‰ê·  ê°’ ê³„ì‚° (ì ìˆ˜ë¥¼ ì´ìš©í•´ì„œ ê·¼ì‚¬ì¹˜ ê³„ì‚°)
        ma_value = price * (1 - score / 100) if price > 0 else 0.0

        return _TickerScore(
            meta=meta,
            price=float(price) if price is not None else 0.0,
            prev_close=float(prev_close) if prev_close is not None else 0.0,
            daily_pct=float(round(daily_pct, 2)) if daily_pct is not None else 0.0,
            score=final_score,
            streak=int(holding_days) if holding_days is not None else 0,
            category=category.strip(),  # ê³µë°± ì œê±°
            ma_value=ma_value,
        )
    except Exception as e:
        logger.exception("%s ì ìˆ˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: %s", meta.ticker, e)
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return _TickerScore(
            meta=meta,
            price=0.0,
            prev_close=0.0,
            daily_pct=0.0,
            score=0.0,
            streak=0,
            category=meta.category if hasattr(meta, "category") else "",
        )


def _resolve_base_date(account_id: str, date_str: Optional[str]) -> pd.Timestamp:
    if date_str:
        try:
            base = pd.to_datetime(date_str).normalize()
        except Exception as exc:
            raise ValueError(f"ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ì…ë‹ˆë‹¤: {date_str}") from exc
    else:
        account_settings = get_account_settings(account_id)
        country_code = (account_settings.get("country_code") or account_id).strip().lower()
        today_norm = pd.Timestamp.now().normalize()
        latest_trading_day = get_latest_trading_day(country_code)
        latest_norm = latest_trading_day.normalize()

        if latest_norm >= today_norm:
            base = latest_norm
        else:
            next_trading_day = get_next_trading_day(country_code, reference_date=today_norm)
            base = next_trading_day if next_trading_day is not None else latest_norm

    return base.normalize()


def _apply_precision(value: float, precision: int) -> float | int:
    if precision <= 0:
        return int(round(value))
    return round(value, precision)


def _resolve_state_phrase(state: str) -> str:
    state_key = (state or "").upper()
    if state_key == "BUY":
        return DECISION_MESSAGES.get("NEW_BUY", "")
    return ""


def _resolve_state_order(state: str) -> int:
    state_key = (state or "").upper()
    cfg = DECISION_CONFIG.get(state_key, {})
    return int(cfg.get("order", 99))


def _join_phrase_parts(*parts: Optional[str]) -> str:
    """Join non-empty phrase components with a separator."""

    cleaned: List[str] = []
    for part in parts:
        if part is None:
            continue
        text = str(part).strip()
        if text:
            cleaned.append(text)
    return " | ".join(cleaned)


def _format_sell_replace_phrase(phrase: str, *, etf_meta: Dict[str, Dict[str, Any]]) -> str:
    if not phrase or "êµì²´ë§¤ë„" not in phrase:
        return phrase

    ratio_match = re.search(r"ì†ìµë¥ \s+[+-]?[0-9.,]+%", phrase)
    ticker_matches = re.findall(r"([A-Za-z0-9:]+)\(ìœ¼\)ë¡œ êµì²´", phrase)

    if not ratio_match or not ticker_matches:
        return phrase

    target_ticker = ticker_matches[-1]
    ratio_text = ratio_match.group(0)
    target_meta = etf_meta.get(target_ticker) or etf_meta.get(target_ticker.upper()) or {}
    target_name = target_meta.get("name") or target_ticker

    return f"êµì²´ë§¤ë„ {ratio_text} - {target_name}({target_ticker})ë¡œ êµì²´"


def _append_risk_off_suffix(phrase: str, ratio: Optional[int]) -> str:
    if ratio is None:
        return phrase
    try:
        ratio_int = int(ratio)
    except (TypeError, ValueError):
        return phrase
    if not (0 <= ratio_int <= 100) or ratio_int >= 100:
        return phrase
    phrase_str = str(phrase or "")
    if "ì‹œì¥ìœ„í—˜íšŒí”¼" in phrase_str:
        return phrase_str
    suffix = f"â—ì‹œì¥ìœ„í—˜íšŒí”¼ ë¹„ì¤‘ì¡°ì ˆâ— (ë³´ìœ ëª©í‘œ {ratio_int}%)"
    return f"{phrase_str} | {suffix}" if phrase_str else suffix


def _normalize_buy_date(value: Any) -> Optional[pd.Timestamp]:
    """Convert various buy date formats into a normalized pandas Timestamp."""

    if value in (None, "", "-"):
        return None
    try:
        ts = pd.to_datetime(value)
    except Exception:
        return None

    if pd.isna(ts):
        return None

    if getattr(ts, "tzinfo", None) is not None:
        try:
            ts = ts.tz_convert(None)  # type: ignore[attr-defined]
        except AttributeError:
            ts = ts.tz_localize(None)  # type: ignore[attr-defined]
    return ts.normalize()


def _resolve_buy_price(
    ticker_data: Dict[str, Any],
    buy_date: Optional[pd.Timestamp],
    *,
    fallback_price: Optional[float] = None,
) -> Optional[float]:
    """Pick the closest available closing price on or before the buy date."""

    if buy_date is None:
        return fallback_price

    close_series = ticker_data.get("close")
    if not isinstance(close_series, pd.Series) or close_series.empty:
        return fallback_price

    series = close_series.dropna().copy()
    if series.empty:
        return fallback_price

    try:
        index = pd.to_datetime(series.index)
    except Exception:
        return fallback_price

    if getattr(index, "tz", None) is not None:
        index = index.tz_localize(None)  # type: ignore[attr-defined]
    index = index.normalize()
    normalized_series = pd.Series(series.values, index=index)
    normalized_series = normalized_series.sort_index()
    normalized_series = normalized_series[~normalized_series.index.duplicated(keep="last")]

    if normalized_series.empty:
        return fallback_price

    prior_or_same = normalized_series.loc[normalized_series.index <= buy_date]
    if not prior_or_same.empty:
        return float(prior_or_same.iloc[-1])

    after = normalized_series.loc[normalized_series.index >= buy_date]
    if not after.empty:
        return float(after.iloc[0])

    return fallback_price


def _compute_trailing_return(
    close_series: pd.Series,
    periods_back: int,
) -> float:
    """Compute percentage return using close price N trading days ago."""

    if not isinstance(close_series, pd.Series) or close_series.empty:
        return 0.0
    valid = close_series.dropna()
    if valid.empty:
        return 0.0

    if len(valid) <= periods_back:
        return 0.0

    try:
        latest_price = float(valid.iloc[-1])
        prev_price = float(valid.iloc[-(periods_back + 1)])
    except (IndexError, TypeError, ValueError):
        return 0.0

    if prev_price <= 0:
        return 0.0

    return round(((latest_price / prev_price) - 1.0) * 100.0, 2)


def _fetch_trades_for_date(account_id: str, base_date: pd.Timestamp) -> List[Dict[str, Any]]:
    """Retrieve trades executed on the given base_date."""

    db = get_db_connection()
    if db is None:
        return []

    start = base_date.to_pydatetime().replace(hour=0, minute=0, second=0, microsecond=0)
    # ìµœì‹  ì¶”ì²œ ì‹¤í–‰ ì‹œ ì‹¤ì œ ê±°ë˜ ì‹œê°„ì´ ê¸°ì¤€ì¼ ë‹¤ìŒ ë‚ ì¼ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ í˜„ì¬ ì‹œê°ê¹Œì§€ í™•ì¥
    end = max(start + timedelta(days=1), datetime.utcnow())

    account_norm = (account_id or "").strip().lower()

    cursor = db.trades.find(
        {
            "account": account_norm,
            "deleted_at": {"$exists": False},
            "executed_at": {"$gte": start, "$lt": end},
        },
        projection={"ticker": 1, "action": 1, "name": 1, "_id": 0},
    )

    trades: List[Dict[str, Any]] = []
    for doc in cursor:
        trades.append(
            {
                "ticker": str(doc.get("ticker") or "").upper(),
                "action": str(doc.get("action") or "").upper(),
                "name": str(doc.get("name") or ""),
            }
        )
    return trades


def generate_account_recommendation_report(account_id: str, date_str: Optional[str] = None) -> RecommendationReport:
    """ê³„ì • ë‹¨ìœ„ ì¶”ì²œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not account_id:
        raise ValueError("account_id ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    account_id = account_id.strip().lower()

    base_date = _resolve_base_date(account_id, date_str)

    try:
        strategy_rules = get_strategy_rules(account_id)
        account_settings = get_account_settings(account_id)
    except AccountSettingsError as exc:
        raise ValueError(str(exc)) from exc

    country_code = account_settings.get("country_code")

    ma_period = int(strategy_rules.ma_period)
    portfolio_topn = int(strategy_rules.portfolio_topn)

    strategy_cfg = account_settings.get("strategy", {}) or {}
    if not isinstance(strategy_cfg, dict):
        strategy_cfg = {}

    if "tuning" in strategy_cfg or "static" in strategy_cfg:
        strategy_static = strategy_cfg.get("static") if isinstance(strategy_cfg.get("static"), dict) else {}
        strategy_tuning = strategy_cfg.get("tuning") if isinstance(strategy_cfg.get("tuning"), dict) else {}
    else:
        strategy_static = strategy_cfg
        strategy_tuning = strategy_cfg

    # ê²€ì¦ì€ get_account_strategy_sectionsì—ì„œ ì´ë¯¸ ì™„ë£Œë¨ - ë°”ë¡œ ì‚¬ìš©
    max_per_category = int(strategy_static["MAX_PER_CATEGORY"])
    rsi_sell_threshold = int(strategy_tuning["OVERBOUGHT_SELL_THRESHOLD"])
    regime_filter_equity_ratio = int(strategy_static["MARKET_REGIME_RISK_OFF_EQUITY_RATIO"])

    # ETF ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    etf_universe = get_etfs(country_code) or []
    logger.info(
        "[%s] ì¶”ì²œ Universe ë¡œë”© ì™„ë£Œ: %dê°œ ì¢…ëª© ë°ì´í„° ì¤€ë¹„",
        account_id.upper(),
        len(etf_universe),
    )
    disabled_tickers = {str(stock.get("ticker") or "").strip().upper() for stock in etf_universe if not bool(stock.get("recommend_enabled", True))}
    pairs = [(stock.get("ticker"), stock.get("name")) for stock in etf_universe if stock.get("ticker")]

    # ì‹¤ì œ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° ì¤€ë¹„
    holdings: Dict[str, Dict[str, float]] = {}
    try:
        # í˜„ì¬ ë¯¸ë§¤ë„ í¬ì§€ì…˜ë§Œ ì¡°íšŒ
        open_positions = list_open_positions(account_id)
        if open_positions:
            for position in open_positions:
                ticker = (position.get("ticker") or "").strip().upper()
                if not ticker:
                    continue
                exec_at = position.get("executed_at")
                buy_date = None
                if exec_at is not None:
                    try:
                        buy_date = pd.to_datetime(exec_at).strftime("%Y-%m-%d")
                    except Exception:
                        buy_date = None
                holdings[ticker] = {
                    "buy_date": buy_date,
                }

        # ì˜ˆì™¸ì ìœ¼ë¡œ í¬ì§€ì…˜ì´ ë¹„ì–´ ìˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ê¸°ì¡´ BUY ì§‘ê³„ë¥¼ ë°±ì—…ìœ¼ë¡œ ì‚¬ìš©
        if not holdings:
            db = get_db_connection()
            if db is not None:
                pipeline = [
                    {"$match": {"account": account_id, "action": "BUY"}},
                    {"$group": {"_id": "$ticker"}},
                    {"$project": {"ticker": "$_id", "_id": 0}},
                ]
                holdings_tickers = [item["ticker"] for item in db.trades.aggregate(pipeline)]
                for ticker in holdings_tickers:
                    ticker_norm = (ticker or "").strip().upper()
                    if not ticker_norm:
                        continue
                    holdings[ticker_norm] = {
                        "buy_date": None,
                    }

        logger.debug("ê³„ì‚°ëœ holdings: %dê°œ ì¢…ëª©", len(holdings))
    except Exception as e:
        logger.error("í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: %s", e)
        holdings = {}

    # ì—°ì† ë³´ìœ  ì •ë³´ ê³„ì‚°
    consecutive_holding_info = calculate_consecutive_holding_info(list(holdings.keys()), account_id, base_date.to_pydatetime())

    # í˜„ì¬ ìì‚°/í˜„ê¸ˆ ì •ë³´ (ì„ì‹œê°’ - ì‹¤ì œ ê³„ì‚° í•„ìš”)
    current_equity = 100_000_000  # ì„ì‹œê°’
    total_cash = 100_000_000  # ì„ì‹œê°’

    # ê° í‹°ì»¤ì˜ í˜„ì¬ ë°ì´í„° ì¤€ë¹„ (ì‹¤ì œ OHLCV ë°ì´í„° ì‚¬ìš©)
    tickers_all = [stock.get("ticker") for stock in etf_universe if stock.get("ticker")]
    prefetched_data: Dict[str, pd.DataFrame] = {}
    months_back = max(12, ma_period)
    warmup_days = int(max(ma_period, 1) * 1.5)

    common_settings = load_common_settings()
    cache_seed_raw = (common_settings or {}).get("CACHE_START_DATE")
    prefetch_start_dt = base_date - pd.DateOffset(months=months_back)
    if cache_seed_raw:
        try:
            cache_seed_dt = pd.to_datetime(cache_seed_raw).normalize()
            if cache_seed_dt > prefetch_start_dt:
                prefetch_start_dt = cache_seed_dt
        except Exception:
            pass
    start_date = prefetch_start_dt.strftime("%Y-%m-%d")
    end_date = base_date.strftime("%Y-%m-%d")
    logger.info(
        "[%s] ê°€ê²© ë°ì´í„° ë¡œë”© ì‹œì‘ (ê¸°ê°„ %s~%s, ëŒ€ìƒ %dê°œ)",
        account_id.upper(),
        start_date,
        end_date,
        len(tickers_all),
    )
    fetch_start = time.perf_counter()
    prefetched_data, missing_prefetch = prepare_price_data(
        tickers=tickers_all,
        country=country_code,
        start_date=start_date,
        end_date=end_date,
        warmup_days=warmup_days,
    )
    logger.info(
        "[%s] ê°€ê²© ë°ì´í„° ë¡œë”© ì™„ë£Œ (%.1fs)",
        account_id.upper(),
        time.perf_counter() - fetch_start,
    )
    missing_logged = set(missing_prefetch)
    if missing_prefetch:
        logger.warning(
            "[%s] ë‹¤ìŒ ì¢…ëª©ì˜ ê°€ê²© ë°ì´í„°ë¥¼ í™•ë³´í•˜ì§€ ëª»í•´ ì œì™¸í•©ë‹ˆë‹¤: %s",
            account_id.upper(),
            ", ".join(sorted(missing_logged)),
        )

    data_by_tkr = {}
    missing_data_tickers: List[str] = list(missing_prefetch)
    for stock in etf_universe:
        ticker = stock["ticker"]
        # ì‹¤ì œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        df = _fetch_dataframe(
            ticker,
            country=country_code,
            ma_period=ma_period,
            base_date=base_date,
            prefetched_data=prefetched_data,
        )
        if df is not None and not df.empty:
            # ìµœì‹  ê°€ê²© ì •ë³´
            latest_close = df["Close"].iloc[-1]
            prev_close = df["Close"].iloc[-2] if len(df) > 1 else latest_close
            latest_data_date = pd.to_datetime(df.index[-1]).normalize()
            base_norm = base_date.normalize()

            daily_pct = 0.0
            if prev_close and prev_close > 0:
                daily_pct = ((latest_close / prev_close) - 1.0) * 100

            if base_norm > latest_data_date:
                prev_close = latest_close
                daily_pct = 0.0

            # MAPS ì „ëµ ê³„ì‚°
            from utils.indicators import calculate_ma_score
            from logic.common import get_buy_signal_streak

            # ì´ë™í‰ê·  ê³„ì‚°
            moving_average = df["Close"].rolling(window=ma_period).mean()

            # ì ìˆ˜ ê³„ì‚°
            ma_score_series = calculate_ma_score(df["Close"], moving_average, normalize=False)
            score = ma_score_series.iloc[-1] if not ma_score_series.empty else 0.0

            # ì§€ì†ì¼ ê³„ì‚° (ì ìˆ˜ ê¸°ë°˜)
            consecutive_buy_days = get_buy_signal_streak(score, ma_score_series)

            # RSI ì „ëµ ê³„ì‚° (strategies/rsi/recommend.pyì—ì„œ ì²˜ë¦¬)
            from strategies.rsi.recommend import calculate_rsi_for_ticker

            rsi_score = calculate_rsi_for_ticker(df["Close"])

            # RSI ê³„ì‚° ì‹¤íŒ¨ ì‹œ ë””ë²„ê¹… ë¡œê·¸
            if rsi_score == 0.0 and len(df["Close"]) < 15:
                logger.warning(f"[RSI] {ticker} ë°ì´í„° ë¶€ì¡±: {len(df['Close'])}ê°œ (ìµœì†Œ 15ê°œ í•„ìš”)")

            recent_prices = df["Close"].tail(15)
            trend_prices = [round(float(val), 6) for val in recent_prices.tolist()] if not recent_prices.empty else []

            data_by_tkr[ticker] = {
                "price": latest_close,
                "prev_close": prev_close,
                "daily_pct": round(daily_pct, 2),
                "close": df["Close"],  # ë°±í…ŒìŠ¤íŠ¸ìš© close ë°ì´í„° ì¶”ê°€
                "s1": moving_average.iloc[-1] if not moving_average.empty else None,
                "s2": None,
                "score": score,
                "rsi_score": rsi_score,
                "filter": consecutive_buy_days,
                "ret_1w": _compute_trailing_return(df["Close"], 5),
                "ret_2w": _compute_trailing_return(df["Close"], 10),
                "ret_3w": _compute_trailing_return(df["Close"], 15),
                "trend_prices": trend_prices,
            }
        else:
            missing_data_tickers.append(ticker)

    if missing_data_tickers:
        extra_missing = set(missing_data_tickers) - missing_logged
        if extra_missing:
            logger.warning(
                "[%s] ë¶„ì„ ì¤‘ ì¶”ê°€ë¡œ ì œì™¸ëœ ì¢…ëª©: %s",
                account_id.upper(),
                ", ".join(sorted(extra_missing)),
            )
        missing_logged.update(missing_data_tickers)

    regime_info = None
    regime_filter_enabled = True
    try:
        common_settings = load_common_settings()
    except Exception as exc:
        logger.warning("ì‹œì¥ ë ˆì§ ê³µí†µ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: %s", exc)
        common_settings = None
    else:
        regime_filter_enabled = bool((common_settings or {}).get("MARKET_REGIME_FILTER_ENABLED", True))
        common_ratio_value = (common_settings or {}).get("MARKET_REGIME_RISK_OFF_EQUITY_RATIO")
        # ê³µí†µ ì„¤ì •ì— ê°’ì´ ìˆìœ¼ë©´ ì‚¬ìš© (ê²€ì¦ì€ ì´ë¯¸ ì™„ë£Œë¨)
        if regime_filter_equity_ratio is None and common_ratio_value is not None:
            regime_filter_equity_ratio = int(common_ratio_value)

    if regime_filter_enabled:
        try:
            regime_info_candidate, _ = get_market_regime_status_info()
        except Exception as exc:
            logger.warning("ì‹œì¥ ë ˆì§ ì •ë³´ ê³„ì‚° ì‹¤íŒ¨: %s", exc)
        else:
            if regime_info_candidate:
                regime_info_candidate["risk_off_equity_ratio"] = regime_filter_equity_ratio
                regime_info = regime_info_candidate

    # ì¿¨ë‹¤ìš´ ì •ë³´ ê³„ì‚°
    trade_cooldown_info = calculate_trade_cooldown_info(
        [stock["ticker"] for stock in etf_universe],
        account_id,
        base_date.to_pydatetime(),
        country_code=country_code,
    )

    # generate_daily_recommendations_for_portfolio í˜¸ì¶œ
    try:
        from strategies.maps import safe_generate_daily_recommendations_for_portfolio

        decision_start = time.perf_counter()
        actual_cooldown_days = int(strategy_tuning["COOLDOWN_DAYS"])
        logger.info(
            "[%s] ì¶”ì²œ ê³„ì‚° ì‹œì‘ (ë³´ìœ  %dê°œ, í›„ë³´ %dê°œ, cooldown_days=%d)",
            account_id.upper(),
            len(holdings),
            len(data_by_tkr),
            actual_cooldown_days,
        )
        decisions = safe_generate_daily_recommendations_for_portfolio(
            account_id=account_id,
            country_code=country_code,
            base_date=base_date,
            strategy_rules=strategy_rules,
            data_by_tkr=data_by_tkr,
            holdings=holdings,
            etf_meta={stock["ticker"]: stock for stock in etf_universe},
            full_etf_meta={stock["ticker"]: stock for stock in etf_universe},
            regime_info=regime_info,
            current_equity=current_equity,
            total_cash=total_cash,
            pairs=pairs,
            consecutive_holding_info=consecutive_holding_info,
            trade_cooldown_info=trade_cooldown_info,
            cooldown_days=actual_cooldown_days,
            risk_off_equity_ratio=regime_filter_equity_ratio,
            rsi_sell_threshold=rsi_sell_threshold,
        )
        logger.info(
            "[%s] ì¶”ì²œ ê³„ì‚° ì™„ë£Œ (%.1fs, ê²°ê³¼ %dê°œ)",
            account_id.upper(),
            time.perf_counter() - decision_start,
            len(decisions) if isinstance(decisions, list) else -1,
        )
    except Exception as exc:
        logger.error("generate_daily_recommendations_for_portfolio ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: %s", exc)
        return []

    # ë‹¹ì¼ SELL íŠ¸ë ˆì´ë“œë¥¼ ê²°ê³¼ì— ì¶”ê°€í•˜ì—¬ SOLD ìƒíƒœë¡œ ë…¸ì¶œ
    trades_today = _fetch_trades_for_date(account_id, base_date)
    sold_entries: List[Dict[str, Any]] = []
    buy_traded_today: set[str] = set()
    for trade in trades_today:
        action = (trade.get("action") or "").strip().upper()
        ticker = (trade.get("ticker") or "").strip().upper()
        if not ticker:
            continue

        if action == "SELL":
            if ticker in holdings:
                # ì—¬ì „íˆ ë³´ìœ  ì¤‘ì´ë©´ SOLDë¡œ í‘œì‹œí•˜ì§€ ì•ŠìŒ
                continue

            existing = next((d for d in decisions if d.get("tkr") == ticker), None)
            if existing:
                existing["state"] = "SOLD"
                if existing.get("row"):
                    existing["row"][4] = "SOLD"
                    existing["row"][-1] = DECISION_MESSAGES["SOLD"]
                existing["buy_signal"] = False
                continue

            name = trade.get("name") or ticker
            ticker_data = data_by_tkr.get(ticker, {})
            if not ticker_data:
                meta_info = next(
                    (stock for stock in etf_universe if stock.get("ticker", "").upper() == ticker),
                    None,
                )
                if meta_info:
                    name = meta_info.get("name") or name
                else:
                    logger.warning("SOLD ì¢…ëª© ë©”íƒ€ë°ì´í„° ì—†ìŒ: %s", ticker)
                    name = ticker

            price_val = ticker_data.get("price", 0.0)
            daily_pct_val = (
                ticker_data.get("daily_pct", 0.0)
                if "daily_pct" in ticker_data
                else (
                    ((ticker_data.get("price", 0.0) / ticker_data.get("prev_close", 1.0)) - 1.0) * 100
                    if ticker_data.get("prev_close", 0.0) > 0
                    else 0.0
                )
            )
            score_val = float(ticker_data.get("score", 0.0) or 0.0)

            sold_entries.append(
                {
                    "state": "SOLD",
                    "tkr": ticker,
                    "score": score_val,
                    "buy_signal": False,
                    "row": [
                        0,
                        ticker,
                        name,
                        "-",
                        "SOLD",
                        "-",
                        price_val,
                        daily_pct_val,
                        0,
                        0.0,
                        0.0,
                        0.0,
                        "-",
                        score_val,
                        "-",
                        DECISION_MESSAGES["SOLD"],
                    ],
                }
            )

        elif action == "BUY":
            buy_traded_today.add(ticker)

        else:
            continue

    # ê²°ê³¼ í¬ë§·íŒ…
    etf_meta_map: Dict[str, Dict[str, Any]] = {}
    for stock in etf_universe:
        ticker = stock.get("ticker")
        if not ticker:
            continue
        upper = str(ticker).upper()
        etf_meta_map[upper] = {
            "ticker": upper,
            "name": stock.get("name") or upper,
            "category": stock.get("category") or "TBD",
        }

    # ì¶”ì²œ ë¹„í™œì„± í‹°ì»¤ë„ ë©”íƒ€ë°ì´í„° ë³´ì™„ìš©ìœ¼ë¡œ í¬í•¨í•œë‹¤
    full_meta_map = _load_full_etf_meta(country_code)
    for ticker, meta in full_meta_map.items():
        upper_ticker = ticker.upper()
        if upper_ticker not in etf_meta_map:
            etf_meta_map[upper_ticker] = {
                "ticker": upper_ticker,
                "name": meta.get("name") or upper_ticker,
                "category": meta.get("category") or "TBD",
            }

    disabled_note = DECISION_NOTES.get("NO_RECOMMEND", "ì¶”ì²œ ì œì™¸")
    results = []
    for decision in decisions:
        ticker = decision["tkr"]
        raw_state = decision["state"]
        phrase = decision["row"][-1] if decision["row"] else ""

        is_currently_held = ticker in holdings

        state = raw_state
        if is_currently_held and raw_state in {"WAIT"}:
            state = "HOLD"

        new_buy_phrase = DECISION_MESSAGES.get("NEW_BUY", "âœ… ì‹ ê·œ ë§¤ìˆ˜")

        if new_buy_phrase in str(phrase):
            state = "BUY"

        phrase = _format_sell_replace_phrase(phrase, etf_meta=etf_meta_map)

        meta_info = etf_meta_map.get(ticker) or {}
        name = meta_info.get("name", ticker)
        category = meta_info.get("category", "TBD")
        ticker_upper = str(ticker).upper()
        recommend_enabled = ticker_upper not in disabled_tickers

        # ë³´ìœ ì¼ ê³„ì‚°
        base_norm = base_date.normalize()
        holding_days_val = 0
        latest_buy_date_norm: Optional[pd.Timestamp] = None
        if ticker in holdings:
            current_date = pd.Timestamp.now().normalize()
            raw_buy_date = consecutive_holding_info.get(ticker, {}).get("buy_date")
            if raw_buy_date:
                buy_timestamp = pd.to_datetime(raw_buy_date).normalize()
                if pd.notna(buy_timestamp):
                    latest_buy_date_norm = buy_timestamp
                    if buy_timestamp <= current_date:
                        holding_days_val = count_trading_days(
                            country_code,
                            buy_timestamp,
                            current_date,
                        )
        elif ticker in consecutive_holding_info:
            buy_date = consecutive_holding_info[ticker].get("buy_date")
            if buy_date:
                buy_timestamp = pd.to_datetime(buy_date).normalize()
                if pd.notna(buy_timestamp) and buy_timestamp <= base_norm:
                    latest_buy_date_norm = buy_timestamp
                    holding_days_val = count_trading_days(
                        country_code,
                        buy_timestamp,
                        base_norm,
                    )

        if latest_buy_date_norm is None:
            fallback_buy_date = holdings.get(ticker, {}).get("buy_date") if ticker in holdings else None
            fallback_norm = _normalize_buy_date(fallback_buy_date)
            if fallback_norm is not None:
                latest_buy_date_norm = fallback_norm

        # ìƒíƒœ ë° ë¬¸êµ¬ ì¬ì •ì˜
        bought_today = False
        if latest_buy_date_norm is not None and latest_buy_date_norm >= base_norm:
            bought_today = True

        # ë‹¹ì¼ ë§¤ìˆ˜ ì²´ê²°ëœ ì¢…ëª© ì²˜ë¦¬
        if ticker in buy_traded_today:
            state = "HOLD"
            new_phrase = DECISION_MESSAGES.get("NEWLY_ADDED", "ğŸ†• ì‹ ê·œ í¸ì…")
            phrase = _append_risk_off_suffix(new_phrase, decision.get("risk_off_target_ratio"))
            if holding_days_val == 0:
                holding_days_val = 1
        # ì¶”ì²œì— ë”°ë¼ ì˜¤ëŠ˜ ì‹ ê·œ ë§¤ìˆ˜í•´ì•¼ í•  ì¢…ëª©
        elif state in {"BUY", "BUY_REPLACE"}:
            phrase_str = str(phrase)
            risk_off_ratio = decision.get("risk_off_target_ratio")

            if state == "BUY_REPLACE":
                replacement_note = phrase_str if phrase_str else ""
                combined_phrase = _join_phrase_parts(DECISION_MESSAGES.get("NEW_BUY", "âœ… ì‹ ê·œ ë§¤ìˆ˜"), replacement_note)
                phrase = _append_risk_off_suffix(combined_phrase, risk_off_ratio)
            else:  # state == "BUY"
                base_new_phrase = DECISION_MESSAGES.get("NEW_BUY", "âœ… ì‹ ê·œ ë§¤ìˆ˜")
                if "ì‹œì¥ìœ„í—˜íšŒí”¼" in phrase_str or phrase_str == DECISION_NOTES.get("RISK_OFF_TRIM"):
                    chosen_phrase = base_new_phrase
                elif phrase_str:
                    chosen_phrase = phrase_str
                else:
                    chosen_phrase = base_new_phrase
                phrase = _append_risk_off_suffix(chosen_phrase, risk_off_ratio)
            if holding_days_val == 0:
                holding_days_val = 1
        # ì´ë¯¸ ë³´ìœ  ì¤‘ì¸ ì¢…ëª©ì´ ì˜¤ëŠ˜ ì‹ ê·œ í¸ì…ëœ ê²½ìš°
        elif is_currently_held and bought_today:
            state = "HOLD"
            new_phrase = DECISION_MESSAGES.get("NEWLY_ADDED", "ğŸ†• ì‹ ê·œ í¸ì…")
            phrase = _append_risk_off_suffix(new_phrase, decision.get("risk_off_target_ratio"))
            if holding_days_val == 0:
                holding_days_val = 1

        ticker_data = data_by_tkr.get(ticker, {})
        price_val = ticker_data.get("price", 0.0)
        daily_pct_val = (
            ticker_data.get("daily_pct", 0.0)
            if "daily_pct" in ticker_data
            else (
                ((ticker_data.get("price", 0.0) / ticker_data.get("prev_close", 1.0)) - 1.0) * 100 if ticker_data.get("prev_close", 0.0) > 0 else 0.0
            )
        )
        score_val = decision.get("score", 0.0)

        evaluation_pct_val: float = 0.0
        if holding_days_val and holding_days_val > 0 and is_currently_held:
            buy_date_raw = consecutive_holding_info.get(ticker, {}).get("buy_date")
            if not buy_date_raw:
                buy_date_raw = holdings.get(ticker, {}).get("buy_date")

            buy_date_norm = _normalize_buy_date(buy_date_raw)
            if buy_date_norm is None and bought_today:
                buy_date_norm = base_date.normalize()

            buy_price = _resolve_buy_price(
                ticker_data,
                buy_date_norm,
                fallback_price=float(price_val) if price_val else None,
            )

            if buy_price and buy_price > 0 and price_val:
                evaluation_pct_val = round(((float(price_val) / buy_price) - 1.0) * 100, 2)

        ret_1w = ticker_data.get("ret_1w", 0.0)
        ret_2w = ticker_data.get("ret_2w", 0.0)
        ret_3w = ticker_data.get("ret_3w", 0.0)

        filter_days = decision.get("filter")
        if filter_days is None:
            filter_days_row = decision.get("row") or []
            if len(filter_days_row) >= 16:
                try:
                    filter_days = int(str(filter_days_row[15]).replace("ì¼", "")) if filter_days_row[15] not in ("-", None) else 0
                except Exception:
                    filter_days = 0
            else:
                filter_days = 0

        streak_val = int(filter_days)

        if not recommend_enabled:
            if state in {"BUY", "BUY_REPLACE"}:
                state = "WAIT"
            phrase = disabled_note

        rsi_score_val = decision.get("rsi_score", 0.0)

        result_entry = {
            "rank": len(results) + 1,
            "ticker": ticker,
            "name": name,
            "category": category,
            "state": state,
            "price": price_val,
            "daily_pct": daily_pct_val,
            "evaluation_pct": evaluation_pct_val,
            "return_1w": ret_1w,
            "return_2w": ret_2w,
            "return_3w": ret_3w,
            "trend_prices": ticker_data.get("trend_prices", []),
            "score": score_val,
            "rsi_score": rsi_score_val,
            "streak": streak_val,
            "base_date": base_date.strftime("%Y-%m-%d"),
            "holding_days": holding_days_val,
            "phrase": phrase,
            "state_order": DECISION_CONFIG.get(state, {}).get("order", 99),
            "recommend_enabled": recommend_enabled,
        }

        results.append(result_entry)

    # BUY ì¢…ëª© ìƒì„±: ìƒìœ„ ì ìˆ˜ì˜ WAIT ì¢…ëª©ë“¤ì„ BUYë¡œ ë³€ê²½
    wait_items = [item for item in results if item["state"] == "WAIT" and item.get("recommend_enabled", True)]
    # MAPS ì ìˆ˜ ê¸°ë°˜ ì •ë ¬
    wait_items.sort(key=lambda x: x.get("score", 0.0), reverse=True)

    # ì¹´í…Œê³ ë¦¬ ë³´ìœ  ì œí•œì´ ìˆëŠ” ê²½ìš°, ë™ì¼ ì¹´í…Œê³ ë¦¬ ìˆ˜ë¥¼ ì²´í¬ (ë§¤ë„ ì˜ˆì • ì¢…ëª© ì œì™¸)
    from logic.common import should_exclude_from_category_count

    category_counts: Dict[str, int] = {}
    category_counts_normalized: Dict[str, int] = {}
    category_limit = max_per_category if max_per_category and max_per_category > 0 else 1
    for item in results:
        # ë§¤ë„ ì˜ˆì • ì¢…ëª©ì€ ì¹´í…Œê³ ë¦¬ ì¹´ìš´íŠ¸ì—ì„œ ì œì™¸
        if not should_exclude_from_category_count(item["state"]) and item["state"] in {"HOLD", "BUY", "BUY_REPLACE"}:
            category_raw = item.get("category")
            category = str(category_raw or "").strip()
            if category:
                category_counts[category] = category_counts.get(category, 0) + 1
            category_key = _normalize_category_value(category_raw)
            if category_key:
                category_counts_normalized[category_key] = category_counts_normalized.get(category_key, 0) + 1

    current_holdings_count = len(holdings)
    sell_state_set = {"SELL_TREND", "SELL_REPLACE", "CUT_STOPLOSS", "SELL_RSI"}
    buy_state_set = {"BUY", "BUY_REPLACE"}
    planned_sell_count = sum(1 for item in results if item["state"] in sell_state_set)
    planned_buy_count = sum(1 for item in results if item["state"] in buy_state_set)

    projected_holdings = current_holdings_count - planned_sell_count + planned_buy_count
    additional_buy_slots = max(0, portfolio_topn - projected_holdings)

    promoted = 0
    for item in wait_items:
        if promoted >= additional_buy_slots:
            break

        category_raw = item.get("category")
        category = str(category_raw or "").strip()
        category_key = _normalize_category_value(category_raw)

        # ì¹´í…Œê³ ë¦¬ ì¤‘ë³µ ì²´í¬ ì‹œ, ë§¤ë„ ì˜ˆì • ì¢…ëª©ì€ ì œì™¸
        # ê°™ì€ ì¹´í…Œê³ ë¦¬ì˜ ë§¤ë„ ì˜ˆì • ì¢…ëª©ì´ ìˆìœ¼ë©´ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ìŠ¬ë¡¯ì´ ë¹„ê²Œ ë¨
        sell_in_same_category = sum(
            1 for r in results if r["state"] in sell_state_set and _normalize_category_value(r.get("category")) == category_key
        )
        effective_category_count = category_counts_normalized.get(category_key, 0) - sell_in_same_category

        if category_key and effective_category_count >= category_limit:
            # ì¹´í…Œê³ ë¦¬ ì¤‘ë³µì¸ ê²½ìš° BUYë¡œ ë³€ê²½í•˜ì§€ ì•Šê³  WAIT ìƒíƒœ ìœ ì§€
            # filter_category_duplicatesì—ì„œ í•„í„°ë§ë¨
            continue

        # RSI ê³¼ë§¤ìˆ˜ ì¢…ëª© ë§¤ìˆ˜ ì°¨ë‹¨
        # rsi_sell_thresholdëŠ” ê³„ì¢Œë³„ ì„¤ì •ì—ì„œ ë¡œë“œë¨ (ì´ í•¨ìˆ˜ ì™¸ë¶€ì—ì„œ ì²˜ë¦¬)
        # ì—¬ê¸°ì„œëŠ” ì´ë¯¸ portfolio.pyì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ ì¶”ê°€ ì²´í¬ ë¶ˆí•„ìš”
        pass

        item["state"] = "BUY"
        item["phrase"] = DECISION_MESSAGES.get("NEW_BUY", "âœ… ì‹ ê·œ ë§¤ìˆ˜")
        promoted += 1

        if category:
            category_counts[category] = category_counts.get(category, 0) + 1
        if category_key:
            category_counts_normalized[category_key] = category_counts_normalized.get(category_key, 0) + 1

        # ì‹ ê·œ ë§¤ìˆ˜ë¡œ ì „í™˜ëœ ì¢…ëª©ì€ holdings ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’ ì¶”ê°€
        holdings.setdefault(
            item["ticker"],
            {
                "buy_date": base_date.strftime("%Y-%m-%d"),
            },
        )

    sell_state_set = {
        "SELL_TREND",
        "SELL_REPLACE",
        "CUT_STOPLOSS",
    }
    buy_state_set = {"BUY", "BUY_REPLACE"}

    planned_sell_count = sum(1 for item in results if (item.get("state") or "").upper() in sell_state_set)
    planned_buy_count = sum(1 for item in results if (item.get("state") or "").upper() in buy_state_set)
    projected_holdings = current_holdings_count - planned_sell_count + planned_buy_count

    if projected_holdings > portfolio_topn:
        logger.debug(
            "Projected holdings (%d) exceed portfolio_topn(%d); trim logic removed",
            projected_holdings,
            portfolio_topn,
        )

    # rankë¥¼ MAPS ì ìˆ˜ ìˆœì„œëŒ€ë¡œ ì¬ì„¤ì •
    results.sort(key=lambda x: x.get("score", 0.0), reverse=True)
    for i, item in enumerate(results, 1):
        item["rank"] = i

    # ìµœì¢… state_order ì¬ê³„ì‚° ë° ìƒíƒœ ì •ë ¬ (ë°±í…ŒìŠ¤íŠ¸ì™€ ë™ì¼í•œ ê¸°ì¤€ ì‚¬ìš©)
    for item in results:
        state_key = (item.get("state") or "").upper()
        item["state_order"] = DECISION_CONFIG.get(state_key, {}).get("order", 99)

    # ê³µí†µ ì •ë ¬ í•¨ìˆ˜ ì‚¬ìš©
    sort_decisions_by_order_and_score(results)

    # sort í›„ rank ì¬ì„¤ì •
    for i, item in enumerate(results, 1):
        item["rank"] = i

    # ì¹´í…Œê³ ë¦¬ë³„ ìµœê³  ì ìˆ˜ë§Œ í‘œì‹œ (êµì²´ ë§¤ë§¤ ì œì™¸)
    results = filter_category_duplicates(results, category_key_getter=_normalize_category_value)

    # ì ìˆ˜ê°€ ìŒìˆ˜ì¸ ì¢…ëª© ì œì™¸
    results = [item for item in results if item.get("score", 0.0) >= 0]

    # rank ì¬ì„¤ì •
    for i, item in enumerate(results, 1):
        item["rank"] = i

    detail_headers = [
        "ìˆœìœ„",
        "í‹°ì»¤",
        "ì¢…ëª©ëª…",
        "ì¹´í…Œê³ ë¦¬",
        "ìƒíƒœ",
        "ë³´ìœ ì¼",
        "ì¼ê°„(%)",
        "í‰ê°€(%)",
        "í˜„ì¬ê°€",
        "1ì£¼(%)",
        "2ì£¼(%)",
        "3ì£¼(%)",
        "ì ìˆ˜",
        "ì§€ì†",
        "ë¬¸êµ¬",
    ]

    detail_rows: List[List[Any]] = []
    for item in results:
        detail_rows.append(
            [
                item.get("rank", 0),
                item.get("ticker"),
                item.get("name"),
                item.get("category"),
                item.get("state"),
                item.get("holding_days"),
                item.get("daily_pct"),
                item.get("evaluation_pct"),
                item.get("price"),
                item.get("return_1w"),
                item.get("return_2w"),
                item.get("return_3w"),
                item.get("score"),
                item.get("streak"),
                item.get("phrase", ""),
            ]
        )

    report = RecommendationReport(
        account_id=account_id,
        country_code=country_code,
        base_date=base_date,
        recommendations=results,
        report_date=datetime.now(),
        summary_data=None,
        header_line=None,
        detail_headers=detail_headers,
        detail_rows=detail_rows,
        detail_extra_lines=None,
        decision_config=DECISION_CONFIG,
    )

    return report


# í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ í•¨ìˆ˜ëª…ì„ ê·¸ëŒ€ë¡œ ì œê³µ
generate_country_recommendation_report = generate_account_recommendation_report


__all__ = [
    "generate_account_recommendation_report",
    "generate_country_recommendation_report",
]


def _normalize_category_value(category: Optional[str]) -> Optional[str]:
    """Normalize category strings for comparison."""
    if category is None:
        return None
    category_str = str(category).strip()
    if not category_str:
        return None
    return category_str.upper()
